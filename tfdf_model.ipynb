{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T21:28:18.970836Z",
     "start_time": "2025-03-28T21:28:18.636756Z"
    }
   },
   "cell_type": "code",
   "source": "!.venv/bin/pip3 install -r requirements.txt",
   "id": "45ae6082f3f0015d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1;31merror\u001B[0m: \u001B[1mexternally-managed-environment\u001B[0m\r\n",
      "\r\n",
      "\u001B[31mÃ—\u001B[0m This environment is externally managed\r\n",
      "\u001B[31mâ•°â”€>\u001B[0m To install Python packages system-wide, try apt install\r\n",
      "\u001B[31m   \u001B[0m python3-xyz, where xyz is the package you are trying to\r\n",
      "\u001B[31m   \u001B[0m install.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a non-Debian-packaged Python package,\r\n",
      "\u001B[31m   \u001B[0m create a virtual environment using python3 -m venv path/to/venv.\r\n",
      "\u001B[31m   \u001B[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\r\n",
      "\u001B[31m   \u001B[0m sure you have python3-full installed.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m If you wish to install a non-Debian packaged Python application,\r\n",
      "\u001B[31m   \u001B[0m it may be easiest to use pipx install xyz, which will manage a\r\n",
      "\u001B[31m   \u001B[0m virtual environment for you. Make sure you have pipx installed.\r\n",
      "\u001B[31m   \u001B[0m \r\n",
      "\u001B[31m   \u001B[0m See /usr/share/doc/python3.12/README.venv for more information.\r\n",
      "\r\n",
      "\u001B[1;35mnote\u001B[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001B[1;36mhint\u001B[0m: See PEP 668 for the detailed specification.\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T22:25:20.984750Z",
     "start_time": "2025-03-28T22:25:19.476744Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers\n",
    "from keras.src.layers import Lambda\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import tensorflow_decision_forests as tfdf\n",
    "import ydf  # Yggdrasil Decision Forests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wurlitzer import sys_pipes\n",
    "import keras.layers as preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import keras_tuner as kt\n",
    "import tqdm as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 18:25:19.643785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743200719.654857    9376 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743200719.658410    9376 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743200719.668039    9376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743200719.668046    9376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743200719.668048    9376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743200719.668049    9376 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-28 18:25:19.671199: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "<p style=\"margin:0px;\">ðŸŒ² Try <a href=\"https://ydf.readthedocs.io/en/latest/\" target=\"_blank\">YDF</a>, the successor of\n",
       "    <a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\">TensorFlow\n",
       "        Decision Forests</a> using the same algorithms but with more features and faster\n",
       "    training!\n",
       "</p>\n",
       "<div style=\"display: flex; flex-wrap: wrap; margin:5px;max-width: 880px;\">\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            Old code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import tensorflow_decision_forests as tfdf\n",
       "\n",
       "tf_ds = tfdf.keras.pd_dataframe_to_tf_dataset(ds, label=\"l\")\n",
       "model = tfdf.keras.RandomForestModel(label=\"l\")\n",
       "model.fit(tf_ds)\n",
       "</pre>\n",
       "    </div>\n",
       "    <div style=\"width: 5px;\"></div>\n",
       "    <div style=\"flex: 1; border-radius: 10px; background-color: F0F0F0; padding: 5px;\">\n",
       "        <p\n",
       "            style=\"font-weight: bold; margin:0px;text-align: center;border-bottom: 1px solid #C0C0C0;margin-bottom: 4px;\">\n",
       "            New code</p>\n",
       "        <pre style=\"overflow-wrap: anywhere; overflow: auto; margin:0px;font-size: 9pt;\">\n",
       "import ydf\n",
       "\n",
       "model = ydf.RandomForestLearner(label=\"l\").train(ds)\n",
       "</pre>\n",
       "    </div>\n",
       "</div>\n",
       "<p style=\"margin:0px;font-size: 9pt;\">(Learn more in the <a\n",
       "        href=\"https://ydf.readthedocs.io/en/latest/tutorial/migrating_to_ydf/\" target=\"_blank\">migration\n",
       "        guide</a>)</p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T22:25:23.361863Z",
     "start_time": "2025-03-28T22:25:23.307104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to avoid TensorFlow using all GPU memory\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        # Set TensorFlow to use only the first GPU (if multiple GPUs available)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "1cbeeb19f955c7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T22:29:46.859680Z",
     "start_time": "2025-03-28T22:29:46.727352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_eval(model, train_ds, test_ds = None):\n",
    "    # Optionally, add evaluation metrics.\n",
    "    model.compile(metrics=[\"mse\"])\n",
    "    rmse = 0\n",
    "\n",
    "    with sys_pipes():\n",
    "        model.fit(x=train_ds)\n",
    "\n",
    "    if test_ds is not None:\n",
    "        evaluation = model.evaluate(x=test_ds, return_dict=True)\n",
    "        rmse = math.sqrt(evaluation[\"mse\"])\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def latlon_to_xyz(lat, lon):\n",
    "    lat, lon = np.radians(lat), np.radians(lon)\n",
    "    x = np.cos(lat) * np.cos(lon)\n",
    "    y = np.cos(lat) * np.sin(lon)\n",
    "    z = np.sin(lat)\n",
    "    return x, y, z\n",
    "\n",
    "# Example: Normalize Cartesian coordinates between 0 and 1\n",
    "def normalize_xyz(x, y, z):\n",
    "    # Normalizing each coordinate to the [0, 1] range\n",
    "    return (x + 1) / 2, (y + 1) / 2, (z + 1) / 2\n",
    "\n",
    "class LatLonToXYZ(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LatLonToXYZ, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        lat, lon = inputs[..., 0], inputs[..., 1]  # Assuming inputs shape is (..., 2)\n",
    "        rad_factor = tf.constant(np.pi / 180, dtype=tf.float32)\n",
    "        lat, lon = lat * rad_factor, lon * rad_factor\n",
    "\n",
    "        x = tf.cos(lat) * tf.cos(lon)\n",
    "        y = tf.cos(lat) * tf.sin(lon)\n",
    "        z = tf.sin(lat)\n",
    "\n",
    "        return tf.stack([x, y, z], axis=-1)\n",
    "\n",
    "class NormalizeXYZ(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NormalizeXYZ, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs + 1) / 2  # Normalize to [0,1] range\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    if dtype == 'string':\n",
    "        index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # TODO\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: tf.compat.as_str_any(x[name]))\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Create a Discretization for our integer indices.\n",
    "    encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "    # layer so we can use them, or include them in the functional model later.\n",
    "    # return lambda feature: encoder(index(feature))\n",
    "\n",
    "    return Lambda(lambda feature: encoder(index(feature)))\n",
    "\n",
    "def dataset_preprocessing(unused_columns, categorical_ft_columns, X_train):\n",
    "    used_columns = []\n",
    "\n",
    "    raw_inputs = {}\n",
    "    processed_inputs = {}\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        dtype = X_train.dtypes[col]\n",
    "        if dtype == \"object\":\n",
    "            dtype = \"string\"\n",
    "        raw_inputs[col] = tf.keras.layers.Input(shape=(1,), name=col, dtype=dtype)\n",
    "        processed_inputs[col] = raw_inputs[col]\n",
    "\n",
    "    processed_inputs[\"phi\"] = raw_inputs[\"total_individuals\"] / raw_inputs[\"total_households\"]\n",
    "    processed_inputs[\"id_area\"] = raw_inputs[\"total_individuals\"] / raw_inputs[\"AREA_SQKM\"]\n",
    "    processed_inputs[\"hs_area\"] = raw_inputs[\"total_households\"] / raw_inputs[\"AREA_SQKM\"]\n",
    "    lon_lat = tf.keras.layers.Concatenate(name=\"lon_lat\")([raw_inputs[\"lon\"], raw_inputs[\"lat\"]])\n",
    "    processed_inputs[\"xyz\"] = NormalizeXYZ()(LatLonToXYZ()(lon_lat))\n",
    "    zone_encoder = get_category_encoding_layer(\"ADM2_ID\", train_ds, \"string\", 100)\n",
    "    processed_inputs[\"zone\"] = zone_encoder(raw_inputs[\"ADM2_ID\"])\n",
    "    processed_cols = [\"total_individuals\", \"total_households\", \"AREA_SQKM\", \"lon\", \"lat\", \"ADM2_ID\"]\n",
    "    new_cols = [\"phi\", \"id_area\", \"hs_area\", \"xyz\", \"zone\"]\n",
    "\n",
    "    all_features = []\n",
    "    for col in X_train.columns:\n",
    "        if col not in unused_columns + processed_cols:\n",
    "            if col in categorical_ft_columns:\n",
    "                all_features.append(tfdf.keras.FeatureUsage(name=col, semantic=tfdf.keras.FeatureSemantic.CATEGORICAL))\n",
    "            else:\n",
    "                all_features.append(tfdf.keras.FeatureUsage(name=col))\n",
    "            used_columns.append(col)\n",
    "\n",
    "    for col in new_cols:\n",
    "        all_features.append(tfdf.keras.FeatureUsage(name=col))\n",
    "        used_columns.append(col)\n",
    "\n",
    "    preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs, name=\"preprocessor\")\n",
    "\n",
    "    return all_features, preprocessor"
   ],
   "id": "6c9c236a46c60459",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T22:29:54.611935Z",
     "start_time": "2025-03-28T22:29:54.371494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = \"temporary\"\n",
    "df = pd.read_csv(f'{ROOT_DIR}/Train.csv')\n",
    "test_df = pd.read_csv(f'{ROOT_DIR}/Test.csv')\n",
    "vocab_df = pd.read_csv(f'{ROOT_DIR}/variable_descriptions.csv')\n",
    "admin_df = pd.read_csv(f'{ROOT_DIR}/zaf_adminboundaries_tabulardata.csv', sep=\";\")\n",
    "\n",
    "admin_df = admin_df[[\"ADM4_PCODE\", \"AREA_SQKM\", \"ADM2_ID\"]] # ADM3_ID\n",
    "admin_df[\"AREA_SQKM\"] = admin_df[\"AREA_SQKM\"].str.replace(\",\", \".\").astype(float)\n",
    "df = pd.merge(df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "test_df = pd.merge(test_df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "train_ds_pd = pd.concat([X_train, y_train], axis=1)\n",
    "test_ds_pd = pd.concat([X_val, y_val], axis=1)\n",
    "label_column = \"target\"\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "default_columns = [\"ward\", \"ADM4_PCODE\"]\n",
    "nn_cols = [\"dw_00\", \"psa_00\", \"lan_00\", \"pg_00\", \"pw_00\", \"stv_00\", \"car_00\", \"lln_00\"]\n",
    "categorical_ft_columns = [\"ADM2_ID\"]\n",
    "\n",
    "ft_columns = [\n",
    "    default_columns + [\"dw_12\", \"dw_13\", \"lan_13\", \"pw_08\", \"pw_07\"],\n",
    "    default_columns + [\"dw_12\", \"dw_13\", \"lan_13\", \"pw_08\", \"pw_07\"] + nn_cols,\n",
    "    default_columns,\n",
    "]"
   ],
   "id": "baaa89ce9b2530a6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743200994.524158    9376 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22178 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-29T12:05:01.960693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_models = {\n",
    "    \"RF\": tfdf.keras.RandomForestModel,\n",
    "    \"GBM\": tfdf.keras.GradientBoostedTreesModel\n",
    "}\n",
    "unused_columns = ft_columns[0]\n",
    "preprocess_function = dataset_preprocessing\n",
    "tuning_logs = {mn: {} for mn in all_models}\n",
    "\n",
    "n_fold = 10\n",
    "kf = KFold(n_splits=n_fold, shuffle=False)\n",
    "hps = []\n",
    "rmse = []\n",
    "# Find best HP\n",
    "for train_index, test_index in tqdm.tqdm(kf.split(X_train), desc=\"Tuning\"):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_fold_train, y_fold_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_fold_train[\"target\"] = y_fold_train\n",
    "    X_fold_test[\"target\"] = y_fold_test\n",
    "    train_fold = tfdf.keras.pd_dataframe_to_tf_dataset(X_fold_train, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "    test_fold = tfdf.keras.pd_dataframe_to_tf_dataset(X_fold_test, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "    for mn, md in all_models.items():\n",
    "        tuner = tfdf.tuner.RandomSearch(num_trials=10, use_predefined_hps=True)\n",
    "        all_features, preprocessor = preprocess_function(unused_columns, categorical_ft_columns, X_train)\n",
    "        tuned_model = md(features=all_features, exclude_non_specified_features=True, preprocessing=preprocessor, task=tfdf.keras.Task.REGRESSION, tuner=tuner)\n",
    "        tuned_model.compile(metrics=[\"mse\"])\n",
    "        tuned_model.fit(train_ds)\n",
    "\n",
    "        rmse = math.sqrt(tuned_model.evaluate(test_ds, return_dict=True, verbose=0)[\"mse\"])\n",
    "        tuning_logs = tuned_model.make_inspector().tuning_logs()\n",
    "        hp = tuning_logs[tuning_logs.best].iloc[0]\n",
    "\n",
    "        model_log = tuning_logs.get(mn, {})\n",
    "        tuning_logs[mn] = {\n",
    "            \"rmse\": model_log.get(\"rmse\", []) + [rmse],\n",
    "            \"hp\": model_log.get(\"hp\", []) + [hp],\n",
    "        }\n",
    "\n",
    "# Eval with best HP\n",
    "for mn, logs in tuning_logs.items():\n",
    "    mean_rmse = np.mean(logs[\"rmse\"])\n",
    "    std_rmse = np.std(logs[\"rmse\"])\n",
    "    best_hp_idx = np.argmin(logs[\"hp\"])\n",
    "    md = all_models[mn]\n",
    "    best_hp = logs[\"hp\"][best_hp_idx]\n",
    "    all_features, preprocessor = preprocess_function(unused_columns, categorical_ft_columns, X_train)\n",
    "    best_model = md(features=all_features, exclude_non_specified_features=True, preprocessing=preprocessor, task=tfdf.keras.Task.REGRESSION, **best_hp)\n",
    "    best_model.compile(metrics=[\"mse\"])\n",
    "    best_model.fit(train_ds)\n",
    "\n",
    "    rmse = math.sqrt(best_model.evaluate(test_ds, return_dict=True, verbose=0)[\"mse\"])\n",
    "    print(f\"{mn}: RMSE: {rmse}, HP MRMSE: {mean_rmse}, HP SMRMSE: {std_rmse}\")\n"
   ],
   "id": "c0232a2772096f7d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning: 0it [00:00, ?it/s]/tmp/ipykernel_9376/4074709627.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_fold_train[\"target\"] = y_fold_train\n",
      "/tmp/ipykernel_9376/4074709627.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_fold_test[\"target\"] = y_fold_test\n",
      "2025-03-29 08:05:02.166406: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The `num_threads` constructor argument is not set and the number of CPU is os.cpu_count()=64 > 32. Setting num_threads to 32. Set num_threads manually to use more than 32 cpus.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `num_threads` constructor argument is not set and the number of CPU is os.cpu_count()=64 > 32. Setting num_threads to 32. Set num_threads manually to use more than 32 cpus.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp_cxgckse as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:00.556848. Found 2257 examples.\n",
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743249902.751999    9376 kernel.cc:782] Start Yggdrasil model training\n",
      "I0000 00:00:1743249902.752022    9376 kernel.cc:783] Collect training examples\n",
      "I0000 00:00:1743249902.752027    9376 kernel.cc:795] Dataspec guide:\n",
      "column_guides {\n",
      "  column_name_pattern: \"^__LABEL$\"\n",
      "  type: NUMERICAL\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_02$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_03$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_04$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_05$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_06$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_07$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_08$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_09$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_10$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^dw_11$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^psa_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^psa_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^psa_02$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^psa_03$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^psa_04$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^stv_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^stv_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^car_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^car_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lln_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lln_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_02$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_03$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_04$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_05$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_06$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_07$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_08$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_09$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_10$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_11$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_12$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lan_14$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pg_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pg_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pg_02$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pg_03$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pg_04$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^lgt_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_00$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_01$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_02$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_03$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_04$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_05$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^pw_06$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^NL$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^phi$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^id_area$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^hs_area$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^xyz$\"\n",
      "}\n",
      "column_guides {\n",
      "  column_name_pattern: \"^zone$\"\n",
      "}\n",
      "default_column_guide {\n",
      "  categorial {\n",
      "    max_vocab_count: 2000\n",
      "  }\n",
      "  discretized_numerical {\n",
      "    maximum_num_bins: 255\n",
      "  }\n",
      "}\n",
      "ignore_columns_without_guides: true\n",
      "detect_numerical_as_discretized_numerical: false\n",
      "\n",
      "I0000 00:00:1743249902.754314    9376 kernel.cc:401] Number of batches: 3\n",
      "I0000 00:00:1743249902.754322    9376 kernel.cc:402] Number of examples: 2257\n",
      "I0000 00:00:1743249902.755028    9376 kernel.cc:802] Training dataset:\n",
      "Number of records: 2257\n",
      "Number of columns: 60\n",
      "\n",
      "Number of columns by type:\n",
      "\tNUMERICAL: 60 (100%)\n",
      "\n",
      "Columns:\n",
      "\n",
      "NUMERICAL: 60 (100%)\n",
      "\t0: \"NL\" NUMERICAL mean:19.2448 min:0 max:63 sd:19.8476\n",
      "\t1: \"__LABEL\" NUMERICAL mean:25.0051 min:0 max:55.5284 sd:10.5774\n",
      "\t2: \"car_00\" NUMERICAL mean:0.255343 min:0 max:0.958672 sd:0.202091\n",
      "\t3: \"car_01\" NUMERICAL mean:0.744657 min:0.041328 max:1 sd:0.202091\n",
      "\t4: \"dw_00\" NUMERICAL mean:0.696468 min:0 max:0.989374 sd:0.221016\n",
      "\t5: \"dw_01\" NUMERICAL mean:0.109109 min:0 max:0.93149 sd:0.198338\n",
      "\t6: \"dw_02\" NUMERICAL mean:0.0364859 min:0 max:0.951806 sd:0.0877054\n",
      "\t7: \"dw_03\" NUMERICAL mean:0.00699458 min:0 max:0.264239 sd:0.0212161\n",
      "\t8: \"dw_04\" NUMERICAL mean:0.0102231 min:0 max:0.392085 sd:0.0337815\n",
      "\t9: \"dw_05\" NUMERICAL mean:0.00577823 min:0 max:0.435912 sd:0.0227049\n",
      "\t10: \"dw_06\" NUMERICAL mean:0.023576 min:0 max:0.412936 sd:0.0379147\n",
      "\t11: \"dw_07\" NUMERICAL mean:0.0382763 min:0 max:0.455815 sd:0.0577564\n",
      "\t12: \"dw_08\" NUMERICAL mean:0.0571095 min:0 max:0.798479 sd:0.103814\n",
      "\t13: \"dw_09\" NUMERICAL mean:0.00722785 min:0 max:0.253522 sd:0.0169311\n",
      "\t14: \"dw_10\" NUMERICAL mean:0.00101186 min:0 max:0.0687517 sd:0.00244838\n",
      "\t15: \"dw_11\" NUMERICAL mean:0.00773975 min:0 max:1 sd:0.0267229\n",
      "\t16: \"hs_area\" NUMERICAL mean:697.508 min:0.0125548 max:32124.6 sd:1514.57\n",
      "\t17: \"id_area\" NUMERICAL mean:2329.87 min:1.03462 max:92450.9 sd:4714.86\n",
      "\t18: \"lan_00\" NUMERICAL mean:0.0683682 min:0 max:0.879655 sd:0.14865\n",
      "\t19: \"lan_01\" NUMERICAL mean:0.066075 min:0 max:0.939549 sd:0.135923\n",
      "\t20: \"lan_02\" NUMERICAL mean:0.0344225 min:0 max:0.895365 sd:0.0992433\n",
      "\t21: \"lan_03\" NUMERICAL mean:0.03877 min:0 max:0.852927 sd:0.0818817\n",
      "\t22: \"lan_04\" NUMERICAL mean:0.350824 min:0 max:0.986159 sd:0.382827\n",
      "\t23: \"lan_05\" NUMERICAL mean:0.138188 min:0 max:0.978779 sd:0.27637\n",
      "\t24: \"lan_06\" NUMERICAL mean:0.125639 min:0 max:0.981207 sd:0.240252\n",
      "\t25: \"lan_07\" NUMERICAL mean:0.0364883 min:0 max:0.815035 sd:0.0950571\n",
      "\t26: \"lan_08\" NUMERICAL mean:0.00481755 min:0 max:0.0342339 sd:0.00489395\n",
      "\t27: \"lan_09\" NUMERICAL mean:0.0258504 min:0 max:0.981233 sd:0.120012\n",
      "\t28: \"lan_10\" NUMERICAL mean:0.0296467 min:0 max:0.982844 sd:0.139911\n",
      "\t29: \"lan_11\" NUMERICAL mean:0.0531929 min:0 max:0.991674 sd:0.160048\n",
      "\t30: \"lan_12\" NUMERICAL mean:0.0130058 min:0 max:0.367785 sd:0.0213615\n",
      "\t31: \"lan_14\" NUMERICAL mean:0.0147118 min:0 max:0.998448 sd:0.0427396\n",
      "\t32: \"lgt_00\" NUMERICAL mean:0.830305 min:0.00247307 max:1 sd:0.216538\n",
      "\t33: \"lln_00\" NUMERICAL mean:0.102733 min:0 max:0.762613 sd:0.138448\n",
      "\t34: \"lln_01\" NUMERICAL mean:0.897267 min:0.237387 max:1 sd:0.138448\n",
      "\t35: \"pg_00\" NUMERICAL mean:0.881529 min:0.0359608 max:1 sd:0.220588\n",
      "\t36: \"pg_01\" NUMERICAL mean:0.0150027 min:0 max:0.899026 sd:0.0551261\n",
      "\t37: \"pg_02\" NUMERICAL mean:0.0220819 min:0 max:0.939564 sd:0.0865251\n",
      "\t38: \"pg_03\" NUMERICAL mean:0.0782566 min:0 max:0.940563 sd:0.177049\n",
      "\t39: \"pg_04\" NUMERICAL mean:0.00313008 min:0 max:0.0983175 sd:0.00468695\n",
      "\t40: \"phi\" NUMERICAL mean:5.54375 min:1.39795 max:3867 sd:81.3027\n",
      "\t41: \"psa_00\" NUMERICAL mean:0.318318 min:0 max:0.561597 sd:0.0776278\n",
      "\t42: \"psa_01\" NUMERICAL mean:0.517921 min:0.00129299 max:0.852493 sd:0.087165\n",
      "\t43: \"psa_02\" NUMERICAL mean:0.000560583 min:0 max:0.019442 sd:0.000838844\n",
      "\t44: \"psa_03\" NUMERICAL mean:0.0351946 min:0 max:0.267377 sd:0.0237432\n",
      "\t45: \"psa_04\" NUMERICAL mean:0.128006 min:0.0427889 max:0.998707 sd:0.0385048\n",
      "\t46: \"pw_00\" NUMERICAL mean:0.373085 min:0 max:0.995907 sd:0.310792\n",
      "\t47: \"pw_01\" NUMERICAL mean:0.320573 min:0 max:0.937595 sd:0.23431\n",
      "\t48: \"pw_02\" NUMERICAL mean:0.119099 min:0 max:1 sd:0.147377\n",
      "\t49: \"pw_03\" NUMERICAL mean:0.0385263 min:0 max:0.327393 sd:0.0526792\n",
      "\t50: \"pw_04\" NUMERICAL mean:0.0187023 min:0 max:0.306787 sd:0.0320178\n",
      "\t51: \"pw_05\" NUMERICAL mean:0.0107189 min:0 max:0.217454 sd:0.0232238\n",
      "\t52: \"pw_06\" NUMERICAL mean:0.119295 min:0 max:0.961523 sd:0.196329\n",
      "\t53: \"stv_00\" NUMERICAL mean:0.231652 min:0 max:0.840486 sd:0.179839\n",
      "\t54: \"stv_01\" NUMERICAL mean:0.768348 min:0.159514 max:1 sd:0.179839\n",
      "\t55: \"xyz.0\" NUMERICAL mean:0.888074 min:0.870339 max:0.90643 sd:0.009815\n",
      "\t56: \"xyz.1\" NUMERICAL mean:0.303347 min:0.27121 max:0.335518 sd:0.0140817\n",
      "\t57: \"xyz.2\" NUMERICAL mean:0.745557 min:0.709209 max:0.771281 sd:0.0115493\n",
      "\t58: \"zone.0\" NUMERICAL mean:1 min:1 max:1 sd:0\n",
      "\t59: \"zone.1\" NUMERICAL mean:0 min:0 max:0 sd:0\n",
      "\n",
      "Terminology:\n",
      "\tnas: Number of non-available (i.e. missing) values.\n",
      "\tood: Out of dictionary.\n",
      "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
      "\ttokenized: The attribute value is obtained through tokenization.\n",
      "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
      "\tvocab-size: Number of unique values.\n",
      "\n",
      "I0000 00:00:1743249902.755056    9376 kernel.cc:818] Configure learner\n",
      "I0000 00:00:1743249902.755224    9376 kernel.cc:831] Training config:\n",
      "learner: \"HYPERPARAMETER_OPTIMIZER\"\n",
      "features: \"^NL$\"\n",
      "features: \"^car_00$\"\n",
      "features: \"^car_01$\"\n",
      "features: \"^dw_00$\"\n",
      "features: \"^dw_01$\"\n",
      "features: \"^dw_02$\"\n",
      "features: \"^dw_03$\"\n",
      "features: \"^dw_04$\"\n",
      "features: \"^dw_05$\"\n",
      "features: \"^dw_06$\"\n",
      "features: \"^dw_07$\"\n",
      "features: \"^dw_08$\"\n",
      "features: \"^dw_09$\"\n",
      "features: \"^dw_10$\"\n",
      "features: \"^dw_11$\"\n",
      "features: \"^hs_area$\"\n",
      "features: \"^id_area$\"\n",
      "features: \"^lan_00$\"\n",
      "features: \"^lan_01$\"\n",
      "features: \"^lan_02$\"\n",
      "features: \"^lan_03$\"\n",
      "features: \"^lan_04$\"\n",
      "features: \"^lan_05$\"\n",
      "features: \"^lan_06$\"\n",
      "features: \"^lan_07$\"\n",
      "features: \"^lan_08$\"\n",
      "features: \"^lan_09$\"\n",
      "features: \"^lan_10$\"\n",
      "features: \"^lan_11$\"\n",
      "features: \"^lan_12$\"\n",
      "features: \"^lan_14$\"\n",
      "features: \"^lgt_00$\"\n",
      "features: \"^lln_00$\"\n",
      "features: \"^lln_01$\"\n",
      "features: \"^pg_00$\"\n",
      "features: \"^pg_01$\"\n",
      "features: \"^pg_02$\"\n",
      "features: \"^pg_03$\"\n",
      "features: \"^pg_04$\"\n",
      "features: \"^phi$\"\n",
      "features: \"^psa_00$\"\n",
      "features: \"^psa_01$\"\n",
      "features: \"^psa_02$\"\n",
      "features: \"^psa_03$\"\n",
      "features: \"^psa_04$\"\n",
      "features: \"^pw_00$\"\n",
      "features: \"^pw_01$\"\n",
      "features: \"^pw_02$\"\n",
      "features: \"^pw_03$\"\n",
      "features: \"^pw_04$\"\n",
      "features: \"^pw_05$\"\n",
      "features: \"^pw_06$\"\n",
      "features: \"^stv_00$\"\n",
      "features: \"^stv_01$\"\n",
      "features: \"^xyz\\\\.0$\"\n",
      "features: \"^xyz\\\\.1$\"\n",
      "features: \"^xyz\\\\.2$\"\n",
      "features: \"^zone\\\\.0$\"\n",
      "features: \"^zone\\\\.1$\"\n",
      "label: \"^__LABEL$\"\n",
      "task: REGRESSION\n",
      "metadata {\n",
      "  framework: \"TF Keras\"\n",
      "}\n",
      "[yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.hyperparameters_optimizer_config] {\n",
      "  base_learner {\n",
      "    learner: \"RANDOM_FOREST\"\n",
      "    features: \"^NL$\"\n",
      "    features: \"^car_00$\"\n",
      "    features: \"^car_01$\"\n",
      "    features: \"^dw_00$\"\n",
      "    features: \"^dw_01$\"\n",
      "    features: \"^dw_02$\"\n",
      "    features: \"^dw_03$\"\n",
      "    features: \"^dw_04$\"\n",
      "    features: \"^dw_05$\"\n",
      "    features: \"^dw_06$\"\n",
      "    features: \"^dw_07$\"\n",
      "    features: \"^dw_08$\"\n",
      "    features: \"^dw_09$\"\n",
      "    features: \"^dw_10$\"\n",
      "    features: \"^dw_11$\"\n",
      "    features: \"^hs_area$\"\n",
      "    features: \"^id_area$\"\n",
      "    features: \"^lan_00$\"\n",
      "    features: \"^lan_01$\"\n",
      "    features: \"^lan_02$\"\n",
      "    features: \"^lan_03$\"\n",
      "    features: \"^lan_04$\"\n",
      "    features: \"^lan_05$\"\n",
      "    features: \"^lan_06$\"\n",
      "    features: \"^lan_07$\"\n",
      "    features: \"^lan_08$\"\n",
      "    features: \"^lan_09$\"\n",
      "    features: \"^lan_10$\"\n",
      "    features: \"^lan_11$\"\n",
      "    features: \"^lan_12$\"\n",
      "    features: \"^lan_14$\"\n",
      "    features: \"^lgt_00$\"\n",
      "    features: \"^lln_00$\"\n",
      "    features: \"^lln_01$\"\n",
      "    features: \"^pg_00$\"\n",
      "    features: \"^pg_01$\"\n",
      "    features: \"^pg_02$\"\n",
      "    features: \"^pg_03$\"\n",
      "    features: \"^pg_04$\"\n",
      "    features: \"^phi$\"\n",
      "    features: \"^psa_00$\"\n",
      "    features: \"^psa_01$\"\n",
      "    features: \"^psa_02$\"\n",
      "    features: \"^psa_03$\"\n",
      "    features: \"^psa_04$\"\n",
      "    features: \"^pw_00$\"\n",
      "    features: \"^pw_01$\"\n",
      "    features: \"^pw_02$\"\n",
      "    features: \"^pw_03$\"\n",
      "    features: \"^pw_04$\"\n",
      "    features: \"^pw_05$\"\n",
      "    features: \"^pw_06$\"\n",
      "    features: \"^stv_00$\"\n",
      "    features: \"^stv_01$\"\n",
      "    features: \"^xyz\\\\.0$\"\n",
      "    features: \"^xyz\\\\.1$\"\n",
      "    features: \"^xyz\\\\.2$\"\n",
      "    features: \"^zone\\\\.0$\"\n",
      "    features: \"^zone\\\\.1$\"\n",
      "    label: \"^__LABEL$\"\n",
      "    task: REGRESSION\n",
      "    random_seed: 123456\n",
      "    pure_serving_model: false\n",
      "    [yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
      "      num_trees: 300\n",
      "      decision_tree {\n",
      "        max_depth: 16\n",
      "        min_examples: 5\n",
      "        in_split_min_examples_check: true\n",
      "        keep_non_leaf_label_distribution: true\n",
      "        num_candidate_attributes: 0\n",
      "        missing_value_policy: GLOBAL_IMPUTATION\n",
      "        allow_na_conditions: false\n",
      "        categorical_set_greedy_forward {\n",
      "          sampling: 0.1\n",
      "          max_num_items: -1\n",
      "          min_item_frequency: 1\n",
      "        }\n",
      "        growing_strategy_local {\n",
      "        }\n",
      "        categorical {\n",
      "          cart {\n",
      "          }\n",
      "        }\n",
      "        axis_aligned_split {\n",
      "        }\n",
      "        internal {\n",
      "          sorting_strategy: PRESORTED\n",
      "        }\n",
      "        uplift {\n",
      "          min_examples_in_treatment: 5\n",
      "          split_score: KULLBACK_LEIBLER\n",
      "        }\n",
      "        numerical_vector_sequence {\n",
      "          max_num_test_examples: 1000\n",
      "          num_random_selected_anchors: 100\n",
      "        }\n",
      "      }\n",
      "      winner_take_all_inference: true\n",
      "      compute_oob_performances: true\n",
      "      compute_oob_variable_importances: false\n",
      "      num_oob_variable_importances_permutations: 1\n",
      "      bootstrap_training_dataset: true\n",
      "      bootstrap_size_ratio: 1\n",
      "      adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
      "      sampling_with_replacement: true\n",
      "    }\n",
      "  }\n",
      "  optimizer {\n",
      "    optimizer_key: \"RANDOM\"\n",
      "    [yggdrasil_decision_forests.model.hyperparameters_optimizer_v2.proto.random] {\n",
      "      num_trials: 10\n",
      "    }\n",
      "  }\n",
      "  base_learner_deployment {\n",
      "    num_threads: 1\n",
      "  }\n",
      "  predefined_search_space {\n",
      "  }\n",
      "}\n",
      "\n",
      "I0000 00:00:1743249902.755299    9376 kernel.cc:834] Deployment config:\n",
      "cache_path: \"/tmp/tmp_cxgckse/working_cache\"\n",
      "num_threads: 32\n",
      "try_resume_training: true\n",
      "\n",
      "I0000 00:00:1743249902.755388 2566119 kernel.cc:895] Train model\n",
      "I0000 00:00:1743249902.755815 2566119 hyperparameters_optimizer.cc:210] Hyperparameter search space:\n",
      "fields {\n",
      "  name: \"split_axis\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"AXIS_ALIGNED\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"SPARSE_OBLIQUE\"\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_projection_density_factor\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        real: 1\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 2\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 3\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 4\n",
      "      }\n",
      "      possible_values {\n",
      "        real: 5\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_normalization\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"NONE\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"STANDARD_DEVIATION\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"MIN_MAX\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  children {\n",
      "    name: \"sparse_oblique_weights\"\n",
      "    discrete_candidates {\n",
      "      possible_values {\n",
      "        categorical: \"BINARY\"\n",
      "      }\n",
      "      possible_values {\n",
      "        categorical: \"CONTINUOUS\"\n",
      "      }\n",
      "    }\n",
      "    parent_discrete_values {\n",
      "      possible_values {\n",
      "        categorical: \"SPARSE_OBLIQUE\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"categorical_algorithm\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"CART\"\n",
      "    }\n",
      "    possible_values {\n",
      "      categorical: \"RANDOM\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"winner_take_all\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      categorical: \"true\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"max_depth\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 12\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 16\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 20\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 25\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 30\n",
      "    }\n",
      "  }\n",
      "}\n",
      "fields {\n",
      "  name: \"min_examples\"\n",
      "  discrete_candidates {\n",
      "    possible_values {\n",
      "      integer: 1\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 2\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 5\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 10\n",
      "    }\n",
      "    possible_values {\n",
      "      integer: 40\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "I0000 00:00:1743249902.755899 2566119 hyperparameters_optimizer.cc:494] Start local tuner with 1 parallel trial(s), each with 32 thread(s)\n",
      "I0000 00:00:1743249902.756273 2566120 random_forest.cc:438] Training random forest on 2257 example(s) and 59 feature(s).\n",
      "I0000 00:00:1743249902.756288 2566120 gpu.cc:93] Cannot initialize GPU: Not compiled with GPU support\n",
      "I0000 00:00:1743249905.687786 2566121 random_forest.cc:865] Train tree 1/300 rmse:4.65694 [index:0 total:2.93s tree:2.93s]\n",
      "I0000 00:00:1743249917.820099 2566121 random_forest.cc:865] Train tree 5/300 rmse:4.19873 [index:4 total:15.06s tree:2.97s]\n",
      "I0000 00:00:1743249930.215423 2566121 random_forest.cc:865] Train tree 9/300 rmse:3.95751 [index:8 total:27.46s tree:3.11s]\n",
      "I0000 00:00:1743249942.271578 2566121 random_forest.cc:865] Train tree 13/300 rmse:3.76074 [index:12 total:39.52s tree:2.90s]\n",
      "I0000 00:00:1743249954.539724 2566121 random_forest.cc:865] Train tree 17/300 rmse:3.68647 [index:16 total:51.78s tree:3.08s]\n",
      "I0000 00:00:1743249966.776833 2566121 random_forest.cc:865] Train tree 21/300 rmse:3.63519 [index:20 total:1m4.02s tree:3.03s]\n",
      "I0000 00:00:1743249978.912189 2566121 random_forest.cc:865] Train tree 25/300 rmse:3.61227 [index:24 total:1m16.16s tree:2.95s]\n",
      "I0000 00:00:1743249991.343323 2566121 random_forest.cc:865] Train tree 29/300 rmse:3.58804 [index:28 total:1m28.59s tree:3.04s]\n",
      "I0000 00:00:1743250003.727137 2566121 random_forest.cc:865] Train tree 33/300 rmse:3.57801 [index:32 total:1m40.97s tree:3.11s]\n",
      "I0000 00:00:1743250015.967221 2566121 random_forest.cc:865] Train tree 37/300 rmse:3.55872 [index:36 total:1m53.21s tree:3.11s]\n",
      "I0000 00:00:1743250028.133648 2566121 random_forest.cc:865] Train tree 41/300 rmse:3.53973 [index:40 total:2m5.38s tree:3.00s]\n",
      "I0000 00:00:1743250040.184618 2566121 random_forest.cc:865] Train tree 45/300 rmse:3.53444 [index:44 total:2m17.43s tree:2.94s]\n",
      "I0000 00:00:1743250052.601343 2566121 random_forest.cc:865] Train tree 49/300 rmse:3.52941 [index:48 total:2m29.85s tree:3.20s]\n",
      "I0000 00:00:1743250064.605891 2566121 random_forest.cc:865] Train tree 53/300 rmse:3.53146 [index:52 total:2m41.85s tree:2.99s]\n",
      "I0000 00:00:1743250076.811771 2566121 random_forest.cc:865] Train tree 57/300 rmse:3.5288 [index:56 total:2m54.06s tree:3.01s]\n",
      "I0000 00:00:1743250089.054093 2566121 random_forest.cc:865] Train tree 61/300 rmse:3.51654 [index:60 total:3m6.30s tree:3.10s]\n",
      "I0000 00:00:1743250101.301597 2566121 random_forest.cc:865] Train tree 65/300 rmse:3.51222 [index:64 total:3m18.55s tree:3.00s]\n",
      "I0000 00:00:1743250113.918785 2566121 random_forest.cc:865] Train tree 69/300 rmse:3.5062 [index:68 total:3m31.16s tree:3.00s]\n",
      "I0000 00:00:1743250126.172003 2566121 random_forest.cc:865] Train tree 73/300 rmse:3.50374 [index:72 total:3m43.42s tree:2.99s]\n",
      "I0000 00:00:1743250138.498193 2566121 random_forest.cc:865] Train tree 77/300 rmse:3.50513 [index:76 total:3m55.74s tree:3.09s]\n",
      "I0000 00:00:1743250150.644635 2566121 random_forest.cc:865] Train tree 81/300 rmse:3.50449 [index:80 total:4m7.89s tree:3.09s]\n",
      "I0000 00:00:1743250163.078849 2566121 random_forest.cc:865] Train tree 85/300 rmse:3.50189 [index:84 total:4m20.32s tree:3.14s]\n",
      "I0000 00:00:1743250175.405969 2566121 random_forest.cc:865] Train tree 89/300 rmse:3.49987 [index:88 total:4m32.65s tree:3.11s]\n",
      "I0000 00:00:1743250187.960585 2566121 random_forest.cc:865] Train tree 93/300 rmse:3.49599 [index:92 total:4m45.20s tree:3.13s]\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tag_id)",
   "language": "python",
   "name": "tag_id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
