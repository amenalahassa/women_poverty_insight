{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T12:22:10.885928Z",
     "start_time": "2025-03-28T12:22:01.048482Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers\n",
    "from keras.src.layers import Lambda\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import tensorflow_decision_forests as tfdf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wurlitzer import sys_pipes\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import keras_tuner as kt\n",
    "import tqdm as tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 08:22:02.394826: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-28 08:22:02.420497: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-28 08:22:03.112807: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-28 08:22:03.113147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-28 08:22:03.163172: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-28 08:22:03.342437: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-28 08:22:03.344810: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-28 08:22:07.663738: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T12:22:10.954871Z",
     "start_time": "2025-03-28T12:22:10.896638Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_eval(model, train_ds, test_ds = None):\n",
    "    # Optionally, add evaluation metrics.\n",
    "    model.compile(metrics=[\"mse\"])\n",
    "    rmse = 0\n",
    "\n",
    "    with sys_pipes():\n",
    "        model.fit(x=train_ds)\n",
    "\n",
    "    if test_ds is not None:\n",
    "        evaluation = model.evaluate(x=test_ds, return_dict=True)\n",
    "        rmse = math.sqrt(evaluation[\"mse\"])\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def latlon_to_xyz(lat, lon):\n",
    "    lat, lon = np.radians(lat), np.radians(lon)\n",
    "    x = np.cos(lat) * np.cos(lon)\n",
    "    y = np.cos(lat) * np.sin(lon)\n",
    "    z = np.sin(lat)\n",
    "    return x, y, z\n",
    "\n",
    "# Example: Normalize Cartesian coordinates between 0 and 1\n",
    "def normalize_xyz(x, y, z):\n",
    "    # Normalizing each coordinate to the [0, 1] range\n",
    "    return (x + 1) / 2, (y + 1) / 2, (z + 1) / 2\n",
    "\n",
    "class LatLonToXYZ(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LatLonToXYZ, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        lat, lon = inputs[..., 0], inputs[..., 1]  # Assuming inputs shape is (..., 2)\n",
    "        rad_factor = tf.constant(np.pi / 180, dtype=tf.float32)\n",
    "        lat, lon = lat * rad_factor, lon * rad_factor\n",
    "\n",
    "        x = tf.cos(lat) * tf.cos(lon)\n",
    "        y = tf.cos(lat) * tf.sin(lon)\n",
    "        z = tf.sin(lat)\n",
    "\n",
    "        return tf.stack([x, y, z], axis=-1)\n",
    "\n",
    "class NormalizeXYZ(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(NormalizeXYZ, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return (inputs + 1) / 2  # Normalize to [0,1] range\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a StringLookup layer which will turn strings into integer indices\n",
    "    if dtype == 'string':\n",
    "        index = preprocessing.StringLookup(max_tokens=max_tokens)\n",
    "    else:\n",
    "        index = preprocessing.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # TODO\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: tf.compat.as_str_any(x[name]))\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Create a Discretization for our integer indices.\n",
    "    encoder = preprocessing.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply one-hot encoding to our indices. The lambda function captures the\n",
    "    # layer so we can use them, or include them in the functional model later.\n",
    "    # return lambda feature: encoder(index(feature))\n",
    "\n",
    "    return Lambda(lambda feature: encoder(index(feature)))\n",
    "\n",
    "def dataset_preprocessing(unused_columns, categorical_ft_columns, X_train):\n",
    "    used_columns = []\n",
    "\n",
    "    raw_inputs = {}\n",
    "    processed_inputs = {}\n",
    "\n",
    "    for col in X_train.columns:\n",
    "        dtype = X_train.dtypes[col]\n",
    "        if col in categorical_ft_columns:\n",
    "            dtype = \"string\"\n",
    "        raw_inputs[col] = tf.keras.layers.Input(shape=(1,), name=col, dtype=dtype)\n",
    "        processed_inputs[col] = raw_inputs[col]\n",
    "\n",
    "    processed_inputs[\"phi\"] = raw_inputs[\"total_individuals\"] / raw_inputs[\"total_households\"]\n",
    "    processed_inputs[\"id_area\"] = raw_inputs[\"total_individuals\"] / raw_inputs[\"AREA_SQKM\"]\n",
    "    processed_inputs[\"hs_area\"] = raw_inputs[\"total_households\"] / raw_inputs[\"AREA_SQKM\"]\n",
    "    lon_lat = tf.keras.layers.Concatenate(name=\"lon_lat\")([raw_inputs[\"lon\"], raw_inputs[\"lat\"]])\n",
    "    processed_inputs[\"xyz\"] = NormalizeXYZ()(LatLonToXYZ()(lon_lat))\n",
    "    zone_encoder = get_category_encoding_layer(\"ADM2_ID\", train_ds, \"string\", 100)\n",
    "    processed_inputs[\"zone\"] = zone_encoder(raw_inputs[\"ADM2_ID\"])\n",
    "    processed_cols = [\"total_individuals\", \"total_households\", \"AREA_SQKM\", \"lon\", \"lat\", \"ADM2_ID\"]\n",
    "    new_cols = [\"phi\", \"id_area\", \"hs_area\", \"xyz\", \"zone\"]\n",
    "\n",
    "    all_features = []\n",
    "    for col in X_train.columns:\n",
    "        if col not in unused_columns + processed_cols:\n",
    "            if col in categorical_ft_columns:\n",
    "                all_features.append(tfdf.keras.FeatureUsage(name=col, semantic=tfdf.keras.FeatureSemantic.CATEGORICAL))\n",
    "            else:\n",
    "                all_features.append(tfdf.keras.FeatureUsage(name=col))\n",
    "            used_columns.append(col)\n",
    "\n",
    "    for col in new_cols:\n",
    "        all_features.append(tfdf.keras.FeatureUsage(name=col))\n",
    "        used_columns.append(col)\n",
    "\n",
    "    preprocessor = tf.keras.Model(inputs=raw_inputs, outputs=processed_inputs, name=\"preprocessor\")\n",
    "\n",
    "    return all_features, preprocessor"
   ],
   "id": "6c9c236a46c60459",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T12:22:12.341914Z",
     "start_time": "2025-03-28T12:22:11.410079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('outputs/Train.csv')\n",
    "test_df = pd.read_csv('outputs/Test.csv')\n",
    "vocab_df = pd.read_csv('variable_descriptions.csv')\n",
    "admin_df = pd.read_csv('zaf_adminboundaries_tabulardata.csv', sep=\";\")\n",
    "\n",
    "admin_df = admin_df[[\"ADM4_PCODE\", \"AREA_SQKM\", \"ADM2_ID\"]] # ADM3_ID\n",
    "admin_df[\"AREA_SQKM\"] = admin_df[\"AREA_SQKM\"].str.replace(\",\", \".\").astype(float)\n",
    "df = pd.merge(df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "test_df = pd.merge(test_df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "\n",
    "X = df.drop(\"target\", axis=1)\n",
    "y = df[\"target\"]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "train_ds_pd = pd.concat([X_train, y_train], axis=1)\n",
    "test_ds_pd = pd.concat([X_val, y_val], axis=1)\n",
    "label_column = \"target\"\n",
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "default_columns = [\"ward\", \"ADM4_PCODE\"]\n",
    "nn_cols = [\"dw_00\", \"psa_00\", \"lan_00\", \"pg_00\", \"pw_00\", \"stv_00\", \"car_00\", \"lln_00\"]\n",
    "categorical_ft_columns = [\"ADM2_ID\"]\n",
    "\n",
    "ft_columns = [\n",
    "    default_columns + [\"dw_12\", \"dw_13\", \"lan_13\", \"pw_08\", \"pw_07\"],\n",
    "    default_columns + [\"dw_12\", \"dw_13\", \"lan_13\", \"pw_08\", \"pw_07\"] + nn_cols,\n",
    "    default_columns,\n",
    "]"
   ],
   "id": "baaa89ce9b2530a6",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-03-28T12:22:24.609429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_models = {\n",
    "    \"RF\": tfdf.keras.RandomForestModel,\n",
    "    \"GBM\": tfdf.keras.GradientBoostedTreesModel\n",
    "}\n",
    "unused_columns = ft_columns[0]\n",
    "preprocess_function = dataset_preprocessing\n",
    "tuning_logs = {mn: {} for mn in all_models}\n",
    "\n",
    "n_fold = 10\n",
    "kf = KFold(n_splits=n_fold, shuffle=False)\n",
    "hps = []\n",
    "rmse = []\n",
    "# Find best HP\n",
    "for train_index, test_index in tqdm.tqdm(kf.split(X_train), desc=\"Tuning\"):\n",
    "    X_fold_train, X_fold_test = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    y_fold_train, y_fold_test = y_train.iloc[train_index], y_train.iloc[test_index]\n",
    "\n",
    "    X_fold_train[\"target\"] = y_fold_train\n",
    "    X_fold_test[\"target\"] = y_fold_test\n",
    "    train_fold = tfdf.keras.pd_dataframe_to_tf_dataset(X_fold_train, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "    test_fold = tfdf.keras.pd_dataframe_to_tf_dataset(X_fold_test, label=label_column, task=tfdf.keras.Task.REGRESSION)\n",
    "\n",
    "    for mn, md in all_models.items():\n",
    "        tuner = tfdf.tuner.RandomSearch(num_trials=100, use_predefined_hps=True)\n",
    "        all_features, preprocessor = preprocess_function(unused_columns, categorical_ft_columns, X_train)\n",
    "        tuned_model = md(features=all_features, exclude_non_specified_features=True, preprocessing=preprocessor, task=tfdf.keras.Task.REGRESSION, tuner=tuner)\n",
    "        tuned_model.compile(metrics=[\"mse\"])\n",
    "        tuned_model.fit(train_ds)\n",
    "\n",
    "        rmse = math.sqrt(tuned_model.evaluate(test_ds, return_dict=True, verbose=0)[\"mse\"])\n",
    "        tuning_logs = tuned_model.make_inspector().tuning_logs()\n",
    "        hp = tuning_logs[tuning_logs.best].iloc[0]\n",
    "\n",
    "        model_log = tuning_logs.get(mn)\n",
    "        tuning_logs[mn] = {\n",
    "            \"rmse\": model_log.get(\"rmse\", []) + [rmse],\n",
    "            \"hp\": model_log.get(\"hp\", []) + [hp],\n",
    "        }\n",
    "\n",
    "# Eval with best HP\n",
    "for mn, logs in tuning_logs.items():\n",
    "    mean_rmse = np.mean(logs[\"rmse\"])\n",
    "    std_rmse = np.std(logs[\"rmse\"])\n",
    "    best_hp_idx = np.argmin(logs[\"hp\"])\n",
    "    md = all_models[mn]\n",
    "    best_hp = logs[\"hp\"][best_hp_idx]\n",
    "    all_features, preprocessor = preprocess_function(unused_columns, categorical_ft_columns, X_train)\n",
    "    best_model = md(features=all_features, exclude_non_specified_features=True, preprocessing=preprocessor, task=tfdf.keras.Task.REGRESSION, **best_hp)\n",
    "    best_model.compile(metrics=[\"mse\"])\n",
    "    best_model.fit(train_ds)\n",
    "\n",
    "    rmse = math.sqrt(best_model.evaluate(test_ds, return_dict=True, verbose=0)[\"mse\"])\n",
    "    print(f\"{mn}: RMSE: {rmse}, HP MRMSE: {mean_rmse}, HP SMRMSE: {std_rmse}\")\n"
   ],
   "id": "c0232a2772096f7d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuning: 0it [00:00, ?it/s]/tmp/ipykernel_33086/3410627355.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_fold_train[\"target\"] = y_fold_train\n",
      "/tmp/ipykernel_33086/3410627355.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_fold_test[\"target\"] = y_fold_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use /tmp/tmp0qqeype5 as temporary training directory\n",
      "Reading training dataset...\n",
      "Training dataset read in 0:00:11.252964. Found 2257 examples.\n",
      "Training model...\n"
     ]
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
