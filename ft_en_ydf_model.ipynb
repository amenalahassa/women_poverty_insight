{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-29T12:13:20.665441Z",
     "start_time": "2025-03-29T12:13:19.280344Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers\n",
    "from keras.src.layers import Lambda\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import ydf  # Yggdrasil Decision Forests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wurlitzer import sys_pipes\n",
    "import keras.layers as preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import tqdm as tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 08:13:19.456046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743250399.467694 2568358 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743250399.471190 2568358 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743250399.481043 2568358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743250399.481052 2568358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743250399.481053 2568358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743250399.481054 2568358 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-29 08:13:19.484395: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:13:20.762226Z",
     "start_time": "2025-03-29T12:13:20.713953Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to avoid TensorFlow using all GPU memory\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        # Set TensorFlow to use only the first GPU (if multiple GPUs available)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "1cbeeb19f955c7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:13:20.836997Z",
     "start_time": "2025-03-29T12:13:20.833548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_eval(model, train_ds, test_ds = None):\n",
    "    # Optionally, add evaluation metrics.\n",
    "    model.compile(metrics=[\"mse\"])\n",
    "    rmse = 0\n",
    "\n",
    "    with sys_pipes():\n",
    "        model.fit(x=train_ds)\n",
    "\n",
    "    if test_ds is not None:\n",
    "        evaluation = model.evaluate(x=test_ds, return_dict=True)\n",
    "        rmse = math.sqrt(evaluation[\"mse\"])\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def latlon_to_xyz(lat, lon):\n",
    "    lat, lon = np.radians(lat), np.radians(lon)\n",
    "    x = np.cos(lat) * np.cos(lon)\n",
    "    y = np.cos(lat) * np.sin(lon)\n",
    "    z = np.sin(lat)\n",
    "    return x, y, z\n",
    "\n",
    "# Example: Normalize Cartesian coordinates between 0 and 1\n",
    "def normalize_xyz(x, y, z):\n",
    "    # Normalizing each coordinate to the [0, 1] range\n",
    "    return (x + 1) / 2, (y + 1) / 2, (z + 1) / 2"
   ],
   "id": "6c9c236a46c60459",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:13:20.937752Z",
     "start_time": "2025-03-29T12:13:20.892557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = \"temporary\"\n",
    "train_df = pd.read_csv(f'{ROOT_DIR}/Train.csv')\n",
    "test_df = pd.read_csv(f'{ROOT_DIR}/Test.csv')\n",
    "vocab_df = pd.read_csv(f'{ROOT_DIR}/variable_descriptions.csv')\n",
    "admin_df = pd.read_csv(f'{ROOT_DIR}/zaf_adminboundaries_tabulardata.csv', sep=\";\")\n",
    "\n",
    "admin_df = admin_df[[\"ADM4_PCODE\", \"AREA_SQKM\", \"ADM2_ID\"]] # ADM3_ID\n",
    "admin_df[\"AREA_SQKM\"] = admin_df[\"AREA_SQKM\"].str.replace(\",\", \".\").astype(float)\n",
    "train_df = pd.merge(train_df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "test_df = pd.merge(test_df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "label_column = \"target\"\n",
    "\n",
    "default_columns = [\"ward\", \"ADM4_PCODE\"]\n",
    "nul_cols = [\"dw_12\", \"dw_13\", \"lan_13\", \"pw_08\", \"pw_07\"] # Columns with null values\n",
    "cat_columns = [\"ADM2_ID\"] # Categorical columns\n",
    "ft_columns = default_columns + cat_columns"
   ],
   "id": "baaa89ce9b2530a6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:24:07.465315Z",
     "start_time": "2025-03-29T12:24:07.461338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "# categorical_encoder = OneHotEncoder(sparse_output=False)\n",
    "def preprocess_df(input_df, is_train=False):\n",
    "    drop_cols = []\n",
    "    df = input_df.copy()\n",
    "    df = df.drop(nul_cols, axis=1)\n",
    "\n",
    "    ## Create a new feature\n",
    "    df[\"phi\"] = df[\"total_individuals\"] / df[\"total_households\"]\n",
    "    df[\"id_area\"] = df[\"total_individuals\"] / df[\"AREA_SQKM\"]\n",
    "    df[\"hs_area\"] = df[\"total_households\"] / df[\"AREA_SQKM\"]\n",
    "\n",
    "    ## Normalize some columns\n",
    "    norm_cols = [\"phi\", \"NL\", \"id_area\", \"hs_area\"]\n",
    "    # norm_cols = [\"NL\"]\n",
    "    df[norm_cols] = scaler.fit_transform(df[norm_cols]) if is_train else scaler.transform(df[norm_cols])\n",
    "\n",
    "    ## Encode categorical columns\n",
    "    # encoded = categorical_encoder.fit_transform(df[cat_columns]) if is_train else categorical_encoder.transform(df[cat_columns])\n",
    "    # encoded_df = pd.DataFrame(encoded, columns=categorical_encoder.get_feature_names_out(cat_columns))\n",
    "    # df = pd.concat([df, encoded_df], axis=1)\n",
    "    drop_cols = drop_cols + cat_columns\n",
    "    \n",
    "    # Transform lat and lon to xyz\n",
    "    df[\"x\"], df[\"y\"], df[\"z\"] = zip(*df.apply(lambda x: latlon_to_xyz(x[\"lat\"], x[\"lon\"]), axis=1))\n",
    "    df[\"x\"], df[\"y\"], df[\"z\"] = zip(*df.apply(lambda x: normalize_xyz(x[\"x\"], x[\"y\"], x[\"z\"]), axis=1))\n",
    "\n",
    "    drop_cols = drop_cols + default_columns\n",
    "    if len(drop_cols) > 0:\n",
    "        df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "## Test preprocess_df\n",
    "# preprocess_df(train_ds_pd, is_train=True).head()"
   ],
   "id": "1359c575af7915c5",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:16:25.635521Z",
     "start_time": "2025-03-29T12:16:06.164028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "X = train_df.drop(label_column, axis=1)\n",
    "y = train_df[label_column]\n",
    "g = train_df[\"ADM2_ID\"]\n",
    "\n",
    "cv_rmse = []\n",
    "test_rmse = []\n",
    "for train_index, test_index in GroupKFold(n_splits=10, shuffle=False).split(X, y, g):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    X_train = preprocess_df(X_train, is_train=True)\n",
    "    X_val = preprocess_df(X_val, is_train=False)\n",
    "    X_train[\"target\"] = y_train\n",
    "    X_val[\"target\"] = y_val\n",
    "\n",
    "    learner = ydf.RandomForestLearner(label=label_column, task=ydf.Task.REGRESSION, num_threads=32)\n",
    "    evaluation = learner.cross_validation(X_train, folds=5)\n",
    "    cv_rmse.append(evaluation.rmse)\n",
    "    evaluation = learner.train(X_train).evaluate(X_val)\n",
    "    test_rmse.append(evaluation.rmse)\n",
    "\n",
    "np.mean(cv_rmse), np.mean(test_rmse), np.std(cv_rmse), np.std(test_rmse)"
   ],
   "id": "2a462bfe90cdaf9e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 2548 examples\n",
      "Model trained in 0:00:00.277396\n",
      "Train model on 2561 examples\n",
      "Model trained in 0:00:00.282709\n",
      "Train model on 2562 examples\n",
      "Model trained in 0:00:00.283482\n",
      "Train model on 2526 examples\n",
      "Model trained in 0:00:00.285608\n",
      "Train model on 2541 examples\n",
      "Model trained in 0:00:00.288202\n",
      "Train model on 2532 examples\n",
      "Model trained in 0:00:00.281403\n",
      "Train model on 2535 examples\n",
      "Model trained in 0:00:00.282745\n",
      "Train model on 2528 examples\n",
      "Model trained in 0:00:00.273338\n",
      "Train model on 2521 examples\n",
      "Model trained in 0:00:00.280801\n",
      "Train model on 2544 examples\n",
      "Model trained in 0:00:00.289750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.523075212059068,\n",
       " 3.863823675978626,\n",
       " 0.061512679308861846,\n",
       " 0.6737346758439062)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I think that the cv inside YDF use shuffle=True",
   "id": "c5b8d9abab7273dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:20:54.720854Z",
     "start_time": "2025-03-29T12:19:37.659111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_models = {\n",
    "    \"GBT\": ydf.GradientBoostedTreesLearner(label=label_column, task=ydf.Task.REGRESSION, num_threads=32),\n",
    "    \"RF\": ydf.RandomForestLearner(label=label_column, task=ydf.Task.REGRESSION, num_threads=32),\n",
    "}\n",
    "\n",
    "for mn, md in all_models.items():\n",
    "    cv_rmse = []\n",
    "    test_rmse = []\n",
    "    for train_index, test_index in GroupKFold(n_splits=10, shuffle=False).split(X, y, g):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        X_train = preprocess_df(X_train, is_train=True)\n",
    "        X_val = preprocess_df(X_val, is_train=False)\n",
    "        X_train[\"target\"] = y_train\n",
    "        X_val[\"target\"] = y_val\n",
    "\n",
    "        evaluation = md.cross_validation(X_train, folds=5)\n",
    "        cv_rmse.append(evaluation.rmse)\n",
    "        evaluation = md.train(X_train).evaluate(X_val)\n",
    "        test_rmse.append(evaluation.rmse)\n",
    "\n",
    "    print(f\"{mn}: {np.mean(cv_rmse):.2f} {np.mean(test_rmse):.2f} {np.std(cv_rmse):.2f} {np.std(test_rmse):.2f}\")"
   ],
   "id": "800386d3d76ead5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 2548 examples\n",
      "Model trained in 0:00:00.841200\n",
      "Train model on 2561 examples\n",
      "Model trained in 0:00:01.292755\n",
      "Train model on 2562 examples\n",
      "Model trained in 0:00:00.835092\n",
      "Train model on 2526 examples\n",
      "Model trained in 0:00:01.147864\n",
      "Train model on 2541 examples\n",
      "Model trained in 0:00:00.909121\n",
      "Train model on 2532 examples\n",
      "Model trained in 0:00:01.348094\n",
      "Train model on 2535 examples\n",
      "Model trained in 0:00:01.026823\n",
      "Train model on 2528 examples\n",
      "Model trained in 0:00:00.969327\n",
      "Train model on 2521 examples\n",
      "Model trained in 0:00:01.380517\n",
      "Train model on 2544 examples\n",
      "Model trained in 0:00:00.352337\n",
      "GBT: 3.37 3.90 0.06 0.66\n",
      "Train model on 2548 examples\n",
      "Model trained in 0:00:00.287515\n",
      "Train model on 2561 examples\n",
      "Model trained in 0:00:00.282815\n",
      "Train model on 2562 examples\n",
      "Model trained in 0:00:00.283240\n",
      "Train model on 2526 examples\n",
      "Model trained in 0:00:00.270677\n",
      "Train model on 2541 examples\n",
      "Model trained in 0:00:00.280512\n",
      "Train model on 2532 examples\n",
      "Model trained in 0:00:00.278196\n",
      "Train model on 2535 examples\n",
      "Model trained in 0:00:00.277585\n",
      "Train model on 2528 examples\n",
      "Model trained in 0:00:00.277631\n",
      "Train model on 2521 examples\n",
      "Model trained in 0:00:00.272419\n",
      "Train model on 2544 examples\n",
      "Model trained in 0:00:00.282638\n",
      "RF: 3.52 3.86 0.06 0.67\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I think that splitting the data with GroupKFold is better because it trains the model with data from one zone and evaluates it with data from another zone. And we can remark that the RF model is better than the GBT mode using this approach.",
   "id": "7bbf02ff4459e510"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I use the default features, excluding the columns with null values and the categorical columns. I also normalize some columns.",
   "id": "c8e4d915a9b7d60a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T12:25:34.032466Z",
     "start_time": "2025-03-29T12:24:16.178064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_models = {\n",
    "    \"GBT\": ydf.GradientBoostedTreesLearner(label=label_column, task=ydf.Task.REGRESSION, num_threads=32),\n",
    "    \"RF\": ydf.RandomForestLearner(label=label_column, task=ydf.Task.REGRESSION, num_threads=32),\n",
    "}\n",
    "\n",
    "for mn, md in all_models.items():\n",
    "    cv_rmse = []\n",
    "    test_rmse = []\n",
    "    for train_index, test_index in GroupKFold(n_splits=10, shuffle=False).split(X, y, g):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        X_train = preprocess_df(X_train, is_train=True)\n",
    "        X_val = preprocess_df(X_val, is_train=False)\n",
    "        X_train[\"target\"] = y_train\n",
    "        X_val[\"target\"] = y_val\n",
    "\n",
    "        evaluation = md.cross_validation(X_train, folds=5)\n",
    "        cv_rmse.append(evaluation.rmse)\n",
    "        evaluation = md.train(X_train).evaluate(X_val)\n",
    "        test_rmse.append(evaluation.rmse)\n",
    "\n",
    "    print(f\"{mn}: {np.mean(cv_rmse):.2f} {np.mean(test_rmse):.2f} {np.std(cv_rmse):.2f} {np.std(test_rmse):.2f}\")"
   ],
   "id": "5d9af7d590f1e858",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 2548 examples\n",
      "Model trained in 0:00:01.470872\n",
      "Train model on 2561 examples\n",
      "Model trained in 0:00:00.602826\n",
      "Train model on 2562 examples\n",
      "Model trained in 0:00:01.533941\n",
      "Train model on 2526 examples\n",
      "Model trained in 0:00:01.166658\n",
      "Train model on 2541 examples\n",
      "Model trained in 0:00:01.453185\n",
      "Train model on 2532 examples\n",
      "Model trained in 0:00:01.415135\n",
      "Train model on 2535 examples\n",
      "Model trained in 0:00:01.475323\n",
      "Train model on 2528 examples\n",
      "Model trained in 0:00:01.169507\n",
      "Train model on 2521 examples\n",
      "Model trained in 0:00:01.066354\n",
      "Train model on 2544 examples\n",
      "Model trained in 0:00:01.386279\n",
      "GBT: 3.29 3.81 0.07 0.56\n",
      "Train model on 2548 examples\n",
      "Model trained in 0:00:00.315993\n",
      "Train model on 2561 examples\n",
      "Model trained in 0:00:00.294629\n",
      "Train model on 2562 examples\n",
      "Model trained in 0:00:00.289265\n",
      "Train model on 2526 examples\n",
      "Model trained in 0:00:00.318273\n",
      "Train model on 2541 examples\n",
      "Model trained in 0:00:00.308953\n",
      "Train model on 2532 examples\n",
      "Model trained in 0:00:00.299581\n",
      "Train model on 2535 examples\n",
      "Model trained in 0:00:00.304758\n",
      "Train model on 2528 examples\n",
      "Model trained in 0:00:00.293748\n",
      "Train model on 2521 examples\n",
      "Model trained in 0:00:00.295899\n",
      "Train model on 2544 examples\n",
      "Model trained in 0:00:00.295411\n",
      "RF: 3.47 3.83 0.06 0.66\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "I add new features to the model. I create a new feature phi, which is the ratio between the total number of individuals and the total number of households. I also create two new features, id_area and hs_area, which are the ratio between the total number of individuals and households and the area of the zone. I normalize these new features. And I also normalize the NL feature. And then I train the model. The best model is GBT with a RMSE of 3.81.",
   "id": "a4e02644a966ad89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T14:34:42.364854Z",
     "start_time": "2025-03-29T13:07:59.773726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_models = {\n",
    "    \"GBT\": ydf.GradientBoostedTreesLearner,\n",
    "    \"RF\": ydf.RandomForestLearner,\n",
    "}\n",
    "\n",
    "## Split data on train and test based on the zone\n",
    "X = train_df.drop(label_column, axis=1)\n",
    "y = train_df[label_column]\n",
    "g = train_df[\"ADM2_ID\"]\n",
    "\n",
    "## Sample a subset of the zone\n",
    "test_g = g.sample(n=6, random_state=42)\n",
    "train_g = g[~g.isin(test_g)]\n",
    "X_train, X_val = X[g.isin(train_g)], X[g.isin(test_g)]\n",
    "y_train, y_val = y[g.isin(train_g)], y[g.isin(test_g)]\n",
    "\n",
    "X_train = preprocess_df(X_train, is_train=True)\n",
    "X_val = preprocess_df(X_val, is_train=False)\n",
    "X_train[\"target\"] = y_train\n",
    "X_val[\"target\"] = y_val\n",
    "\n",
    "\n",
    "for mn, md in all_models.items():\n",
    "    tuner = ydf.RandomSearchTuner(num_trials=20, automatic_search_space=True)\n",
    "    model = md(label=label_column, task=ydf.Task.REGRESSION, num_threads=32, tuner=tuner)\n",
    "    trainer = model.train(ds=X_train, valid=X_val if mn == \"GBT\" else None)\n",
    "    evaluation = trainer.evaluate(X_val)\n",
    "    outputs[mn] = {\n",
    "        \"evaluation\": evaluation,\n",
    "        \"hp\": model,\n",
    "        \"tuner\": tuner,\n",
    "    }\n",
    "\n",
    "    print(f\"{mn}: {evaluation.rmse:.2f}\")"
   ],
   "id": "14dd25943dac0a92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 2509 training examples and 313 validation examples\n",
      "Model trained in 0:18:43.727930\n",
      "GBT: 3.02\n",
      "Train model on 2509 examples\n",
      "Model trained in 1:07:58.387279\n",
      "RF: 3.18\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T15:43:27.868836Z",
     "start_time": "2025-03-29T15:43:26.436633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model_name = \"GBT\"\n",
    "best_hp = outputs[best_model_name][\"hp\"].hyperparameters\n",
    "best_model = all_models[best_model_name](label=label_column, task=ydf.Task.REGRESSION, num_threads=32, **best_hp)\n",
    "trainer = best_model.train(ds=X_train)\n",
    "evaluation = trainer.evaluate(X_val)\n"
   ],
   "id": "19bb4a4d63c644af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 2509 examples\n",
      "Model trained in 0:00:01.414367\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T15:44:53.839588Z",
     "start_time": "2025-03-29T15:44:53.835300Z"
    }
   },
   "cell_type": "code",
   "source": "len(X_train.columns), len(X_val.columns)",
   "id": "f80d89547e2b683b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 63)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T15:44:25.125740Z",
     "start_time": "2025-03-29T15:44:25.120407Z"
    }
   },
   "cell_type": "code",
   "source": "len(trainer.input_features()), len(trainer.input_feature_names())",
   "id": "4b8763b008ee897b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 62)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T15:45:41.314848Z",
     "start_time": "2025-03-29T15:45:41.303496Z"
    }
   },
   "cell_type": "code",
   "source": "[col for col in X_train.columns if col not in trainer.input_feature_names()]",
   "id": "246667a9b322f682",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T15:38:12.000068Z",
     "start_time": "2025-03-29T15:38:11.986800Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.describe()",
   "id": "fe701e5333e098a7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ydf.utils.html.HtmlNotebookDisplay at 0x7c9ce2311e20>"
      ],
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       ".tab_block .header {\n",
       "    flex-direction: row;\n",
       "    display: flex;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab {\n",
       "    cursor: pointer;\n",
       "    background-color: #F6F5F5;\n",
       "    text-decoration: none;\n",
       "    text-align: center;\n",
       "    padding: 4px 12px;\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab.selected {\n",
       "    border-bottom: 2px solid #2F80ED;\n",
       "}\n",
       "\n",
       ".tab_block .header .tab:hover {\n",
       "    text-decoration: none;\n",
       "    background-color: #DCDCDC;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content {\n",
       "    display: none;\n",
       "    padding: 5px;\n",
       "}\n",
       "\n",
       ".tab_block .body .tab_content.selected {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".ydf_pre {\n",
       "    font-size: medium;\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       ".variable_importance {\n",
       "}\n",
       "\n",
       ".variable_importance select {\n",
       "}\n",
       "\n",
       ".variable_importance .content {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".variable_importance .content.selected {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table {\n",
       "  border-collapse: collapse;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table th {\n",
       "  background-color: #ededed;\n",
       "  font-weight: bold;\n",
       "  text-align: left;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table td {\n",
       "  text-align: right;\n",
       "  padding: 3px 4px;\n",
       "  border: 1px solid lightgray;\n",
       "}\n",
       "\n",
       ".ydf_tuning_table .best {\n",
       "  background-color: khaki;\n",
       "}\n",
       "\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "\n",
       "function ydfShowTab(block_id, item) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    \n",
       "    \n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab selected\"));\n",
       "    console.log(\"HIDE first of:\",block.getElementsByClassName(\"tab_content selected\"));\n",
       "    \n",
       "    block.getElementsByClassName(\"tab selected\")[0].classList.remove(\"selected\");\n",
       "    block.getElementsByClassName(\"tab_content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_\" + item).classList.add(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "  \n",
       "\n",
       "function ydfShowVariableImportance(block_id) {\n",
       "    const block = document.getElementById(block_id);\n",
       "    const item = block.getElementsByTagName(\"select\")[0].value;\n",
       "    block.getElementsByClassName(\"content selected\")[0].classList.remove(\"selected\");\n",
       "    document.getElementById(block_id + \"_body_\" + item).classList.add(\"selected\");\n",
       "}\n",
       "\n",
       "</script>\n",
       "  <div class=\"tab_block\" id=\"1bed-4c80-d5c9-1626\"><div class=\"header\"><a id=\"1bed-4c80-d5c9-1626_model\" class=\"tab selected\" onclick=\"ydfShowTab('1bed-4c80-d5c9-1626', 'model')\">Model</a><a id=\"1bed-4c80-d5c9-1626_dataspec\" class=\"tab\" onclick=\"ydfShowTab('1bed-4c80-d5c9-1626', 'dataspec')\">Dataspec</a><a id=\"1bed-4c80-d5c9-1626_training\" class=\"tab\" onclick=\"ydfShowTab('1bed-4c80-d5c9-1626', 'training')\">Training</a><a id=\"1bed-4c80-d5c9-1626_variable_importance\" class=\"tab\" onclick=\"ydfShowTab('1bed-4c80-d5c9-1626', 'variable_importance')\">Variable importances</a><a id=\"1bed-4c80-d5c9-1626_structure\" class=\"tab\" onclick=\"ydfShowTab('1bed-4c80-d5c9-1626', 'structure')\">Structure</a></div><div class=\"body\"><div id=\"1bed-4c80-d5c9-1626_body_model\" class=\"tab_content selected\"><b>Name</b> : GRADIENT_BOOSTED_TREES<br><b>Task</b> : REGRESSION<br><b>Label</b> : target<br><b>Features (62)</b> : total_households total_individuals dw_00 dw_01 dw_02 dw_03 dw_04 dw_05 dw_06 dw_07 dw_08 dw_09 dw_10 dw_11 psa_00 psa_01 psa_02 psa_03 psa_04 stv_00 stv_01 car_00 car_01 lln_00 lln_01 lan_00 lan_01 lan_02 lan_03 lan_04 lan_05 lan_06 lan_07 lan_08 lan_09 lan_10 lan_11 lan_12 lan_14 pg_00 pg_01 pg_02 pg_03 pg_04 lgt_00 pw_00 pw_01 pw_02 pw_03 pw_04 pw_05 pw_06 lat lon NL AREA_SQKM phi id_area hs_area x y z<br><b>Weights</b> : None<br><b>Trained with tuner</b> : No<br><b>Model size</b> : 2254 kB<br></div><div id=\"1bed-4c80-d5c9-1626_body_dataspec\" class=\"tab_content\"><pre class=\"ydf_pre\">Number of records: 2509\n",
       "Number of columns: 63\n",
       "\n",
       "Number of columns by type:\n",
       "\tNUMERICAL: 63 (100%)\n",
       "\n",
       "Columns:\n",
       "\n",
       "NUMERICAL: 63 (100%)\n",
       "\t0: &quot;target&quot; NUMERICAL mean:24.5948 min:0 max:55.5284 sd:10.4808 dtype:DTYPE_FLOAT64\n",
       "\t1: &quot;total_households&quot; NUMERICAL mean:3563.46 min:1 max:39684.9 sd:3203.16 dtype:DTYPE_FLOAT64\n",
       "\t2: &quot;total_individuals&quot; NUMERICAL mean:12450.9 min:402 max:91716.8 sd:9160.04 dtype:DTYPE_FLOAT64\n",
       "\t3: &quot;dw_00&quot; NUMERICAL mean:0.716421 min:0 max:0.994962 sd:0.212925 dtype:DTYPE_FLOAT64\n",
       "\t4: &quot;dw_01&quot; NUMERICAL mean:0.0915326 min:0 max:0.93149 sd:0.178247 dtype:DTYPE_FLOAT64\n",
       "\t5: &quot;dw_02&quot; NUMERICAL mean:0.0306473 min:0 max:0.951806 sd:0.0765706 dtype:DTYPE_FLOAT64\n",
       "\t6: &quot;dw_03&quot; NUMERICAL mean:0.00604946 min:0 max:0.264239 sd:0.0198126 dtype:DTYPE_FLOAT64\n",
       "\t7: &quot;dw_04&quot; NUMERICAL mean:0.00901387 min:0 max:0.392085 sd:0.032155 dtype:DTYPE_FLOAT64\n",
       "\t8: &quot;dw_05&quot; NUMERICAL mean:0.006014 min:0 max:0.435912 sd:0.0248563 dtype:DTYPE_FLOAT64\n",
       "\t9: &quot;dw_06&quot; NUMERICAL mean:0.0227282 min:0 max:0.412936 sd:0.0379075 dtype:DTYPE_FLOAT64\n",
       "\t10: &quot;dw_07&quot; NUMERICAL mean:0.0393638 min:0 max:0.455815 sd:0.0592548 dtype:DTYPE_FLOAT64\n",
       "\t11: &quot;dw_08&quot; NUMERICAL mean:0.0623085 min:0 max:0.798479 sd:0.110048 dtype:DTYPE_FLOAT64\n",
       "\t12: &quot;dw_09&quot; NUMERICAL mean:0.0070199 min:0 max:0.282843 sd:0.0171421 dtype:DTYPE_FLOAT64\n",
       "\t13: &quot;dw_10&quot; NUMERICAL mean:0.00113556 min:0 max:0.0687517 sd:0.00310055 dtype:DTYPE_FLOAT64\n",
       "\t14: &quot;dw_11&quot; NUMERICAL mean:0.00776534 min:0 max:1 sd:0.0259067 dtype:DTYPE_FLOAT64\n",
       "\t15: &quot;psa_00&quot; NUMERICAL mean:0.312818 min:0 max:0.561597 sd:0.0782693 dtype:DTYPE_FLOAT64\n",
       "\t16: &quot;psa_01&quot; NUMERICAL mean:0.524984 min:0.00129299 max:0.852493 sd:0.0870035 dtype:DTYPE_FLOAT64\n",
       "\t17: &quot;psa_02&quot; NUMERICAL mean:0.000547389 min:0 max:0.019442 sd:0.000857936 dtype:DTYPE_FLOAT64\n",
       "\t18: &quot;psa_03&quot; NUMERICAL mean:0.0331421 min:0 max:0.267377 sd:0.0229881 dtype:DTYPE_FLOAT64\n",
       "\t19: &quot;psa_04&quot; NUMERICAL mean:0.128509 min:0.0427889 max:0.998707 sd:0.0364621 dtype:DTYPE_FLOAT64\n",
       "\t20: &quot;stv_00&quot; NUMERICAL mean:0.225628 min:0 max:0.840486 sd:0.173596 dtype:DTYPE_FLOAT64\n",
       "\t21: &quot;stv_01&quot; NUMERICAL mean:0.774372 min:0.159514 max:1 sd:0.173596 dtype:DTYPE_FLOAT64\n",
       "\t22: &quot;car_00&quot; NUMERICAL mean:0.250724 min:0 max:0.958672 sd:0.193666 dtype:DTYPE_FLOAT64\n",
       "\t23: &quot;car_01&quot; NUMERICAL mean:0.749276 min:0.041328 max:1 sd:0.193666 dtype:DTYPE_FLOAT64\n",
       "\t24: &quot;lln_00&quot; NUMERICAL mean:0.0932606 min:0 max:0.743547 sd:0.125179 dtype:DTYPE_FLOAT64\n",
       "\t25: &quot;lln_01&quot; NUMERICAL mean:0.906739 min:0.256453 max:1 sd:0.125179 dtype:DTYPE_FLOAT64\n",
       "\t26: &quot;lan_00&quot; NUMERICAL mean:0.103088 min:0 max:0.979246 sd:0.211294 dtype:DTYPE_FLOAT64\n",
       "\t27: &quot;lan_01&quot; NUMERICAL mean:0.0524959 min:0 max:0.837394 sd:0.108474 dtype:DTYPE_FLOAT64\n",
       "\t28: &quot;lan_02&quot; NUMERICAL mean:0.0320318 min:0 max:0.895365 sd:0.0945508 dtype:DTYPE_FLOAT64\n",
       "\t29: &quot;lan_03&quot; NUMERICAL mean:0.0346669 min:0 max:0.797872 sd:0.0682423 dtype:DTYPE_FLOAT64\n",
       "\t30: &quot;lan_04&quot; NUMERICAL mean:0.283943 min:0 max:0.986159 sd:0.36932 dtype:DTYPE_FLOAT64\n",
       "\t31: &quot;lan_05&quot; NUMERICAL mean:0.130881 min:0 max:0.978779 sd:0.267358 dtype:DTYPE_FLOAT64\n",
       "\t32: &quot;lan_06&quot; NUMERICAL mean:0.101451 min:0 max:0.981207 sd:0.209191 dtype:DTYPE_FLOAT64\n",
       "\t33: &quot;lan_07&quot; NUMERICAL mean:0.114399 min:0 max:0.960652 sd:0.236259 dtype:DTYPE_FLOAT64\n",
       "\t34: &quot;lan_08&quot; NUMERICAL mean:0.00436162 min:0 max:0.0340955 sd:0.00435535 dtype:DTYPE_FLOAT64\n",
       "\t35: &quot;lan_09&quot; NUMERICAL mean:0.0272497 min:0 max:0.981233 sd:0.12413 dtype:DTYPE_FLOAT64\n",
       "\t36: &quot;lan_10&quot; NUMERICAL mean:0.0271797 min:0 max:0.982844 sd:0.132922 dtype:DTYPE_FLOAT64\n",
       "\t37: &quot;lan_11&quot; NUMERICAL mean:0.0605128 min:0 max:0.991674 sd:0.170446 dtype:DTYPE_FLOAT64\n",
       "\t38: &quot;lan_12&quot; NUMERICAL mean:0.013064 min:0 max:0.367785 sd:0.0216602 dtype:DTYPE_FLOAT64\n",
       "\t39: &quot;lan_14&quot; NUMERICAL mean:0.0146762 min:0 max:0.998448 sd:0.041012 dtype:DTYPE_FLOAT64\n",
       "\t40: &quot;pg_00&quot; NUMERICAL mean:0.862666 min:0.0110533 max:1 sd:0.248502 dtype:DTYPE_FLOAT64\n",
       "\t41: &quot;pg_01&quot; NUMERICAL mean:0.0436553 min:0 max:0.969519 sd:0.149587 dtype:DTYPE_FLOAT64\n",
       "\t42: &quot;pg_02&quot; NUMERICAL mean:0.0140066 min:0 max:0.808129 sd:0.0582663 dtype:DTYPE_FLOAT64\n",
       "\t43: &quot;pg_03&quot; NUMERICAL mean:0.0758714 min:0 max:0.940563 sd:0.171266 dtype:DTYPE_FLOAT64\n",
       "\t44: &quot;pg_04&quot; NUMERICAL mean:0.00380072 min:0 max:0.367842 sd:0.0113984 dtype:DTYPE_FLOAT64\n",
       "\t45: &quot;lgt_00&quot; NUMERICAL mean:0.834934 min:0.0016915 max:1 sd:0.206585 dtype:DTYPE_FLOAT64\n",
       "\t46: &quot;pw_00&quot; NUMERICAL mean:0.352558 min:0 max:0.995907 sd:0.30279 dtype:DTYPE_FLOAT64\n",
       "\t47: &quot;pw_01&quot; NUMERICAL mean:0.338892 min:0 max:0.937595 sd:0.239051 dtype:DTYPE_FLOAT64\n",
       "\t48: &quot;pw_02&quot; NUMERICAL mean:0.124229 min:0 max:1 sd:0.154657 dtype:DTYPE_FLOAT64\n",
       "\t49: &quot;pw_03&quot; NUMERICAL mean:0.0411576 min:0 max:0.327393 sd:0.0572194 dtype:DTYPE_FLOAT64\n",
       "\t50: &quot;pw_04&quot; NUMERICAL mean:0.0197937 min:0 max:0.306787 sd:0.0335503 dtype:DTYPE_FLOAT64\n",
       "\t51: &quot;pw_05&quot; NUMERICAL mean:0.0112888 min:0 max:0.217454 sd:0.0240893 dtype:DTYPE_FLOAT64\n",
       "\t52: &quot;pw_06&quot; NUMERICAL mean:0.11208 min:0 max:0.961523 sd:0.186406 dtype:DTYPE_FLOAT64\n",
       "\t53: &quot;lat&quot; NUMERICAL mean:-26.7315 min:-32.4901 max:-22.3313 sd:1.99531 dtype:DTYPE_FLOAT64\n",
       "\t54: &quot;lon&quot; NUMERICAL mean:28.7008 min:16.76 max:32.8582 sd:2.39174 dtype:DTYPE_FLOAT64\n",
       "\t55: &quot;NL&quot; NUMERICAL mean:0.271616 min:0 max:1 sd:0.298321 dtype:DTYPE_FLOAT64\n",
       "\t56: &quot;AREA_SQKM&quot; NUMERICAL mean:287.715 min:0.227161 max:27812.2 sd:1194.06 dtype:DTYPE_FLOAT64\n",
       "\t57: &quot;phi&quot; NUMERICAL mean:0.00105776 min:0 max:1 sd:0.0199481 dtype:DTYPE_FLOAT64\n",
       "\t58: &quot;id_area&quot; NUMERICAL mean:0.0224705 min:0 max:1 sd:0.0484107 dtype:DTYPE_FLOAT64\n",
       "\t59: &quot;hs_area&quot; NUMERICAL mean:0.0192142 min:0 max:1 sd:0.0444266 dtype:DTYPE_FLOAT64\n",
       "\t60: &quot;x&quot; NUMERICAL mean:0.891092 min:0.870339 max:0.919664 sd:0.00995991 dtype:DTYPE_FLOAT64\n",
       "\t61: &quot;y&quot; NUMERICAL mean:0.714198 min:0.626385 max:0.741851 sd:0.0174466 dtype:DTYPE_FLOAT64\n",
       "\t62: &quot;z&quot; NUMERICAL mean:0.275231 min:0.231423 max:0.310019 sd:0.015539 dtype:DTYPE_FLOAT64\n",
       "\n",
       "Terminology:\n",
       "\tnas: Number of non-available (i.e. missing) values.\n",
       "\tood: Out of dictionary.\n",
       "\tmanually-defined: Attribute whose type is manually defined by the user, i.e., the type was not automatically inferred.\n",
       "\ttokenized: The attribute value is obtained through tokenization.\n",
       "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
       "\tvocab-size: Number of unique values.\n",
       "</pre></div><div id=\"1bed-4c80-d5c9-1626_body_training\" class=\"tab_content\"><p>The following evaluation is computed on the validation or out-of-bag dataset.</p><pre class=\"ydf_pre\">Number of predictions (with weights): 1\n",
       "Task: REGRESSION\n",
       "Loss (SQUARED_ERROR): 3.09373\n",
       "\n",
       "RMSE: 1.7589\n",
       "Default RMSE: : 0\n",
       "</pre><div style='display: grid; gap: 0px; grid-auto-columns: min-content;'><div style='grid-row:1 / span 1; grid-column:1 / span 1;'><script src='https://www.gstatic.com/external_hosted/plotly/plotly.min.js'></script>\n",
       "<div id=\"chart_1bed_4c80_d5c9_1626self_eval_item0\" style=\"display: inline-block;\" ></div>\n",
       "<script>\n",
       "  Plotly.newPlot(\n",
       "    'chart_1bed_4c80_d5c9_1626self_eval_item0',\n",
       "    [{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253],\n",
       "y: [9.54496,8.75996,8.05847,7.43731,6.88201,6.39548,5.95477,5.5684,5.22204,4.90593,4.62768,4.37758,4.14785,3.94355,3.76465,3.60456,3.46105,3.33642,3.22633,3.12203,3.03126,2.9442,2.86585,2.79718,2.73046,2.66972,2.62021,2.5734,2.52058,2.4709,2.43823,2.40179,2.35831,2.32557,2.28771,2.25648,2.233,2.20624,2.1924,2.17029,2.14648,2.11693,2.09394,2.06671,2.05293,2.04022,2.02814,2.01794,2.00412,1.99402,1.9868,1.97048,1.95653,1.95163,1.94604,1.92896,1.91577,1.91191,1.90273,1.88713,1.86877,1.85749,1.84807,1.84366,1.82866,1.82035,1.81516,1.80138,1.7843,1.77773,1.7709,1.76434,1.74896,1.73351,1.72607,1.71951,1.7098,1.70057,1.69336,1.68082,1.66609,1.66115,1.64984,1.64347,1.63475,1.6251,1.6064,1.59207,1.58828,1.57633,1.56624,1.56034,1.55187,1.53818,1.5258,1.52151,1.51607,1.51318,1.50352,1.49576,1.48304,1.47578,1.46798,1.46378,1.45782,1.44703,1.44316,1.43704,1.42924,1.42703,1.42025,1.40825,1.40095,1.39546,1.39027,1.38558,1.38241,1.37494,1.36785,1.35627,1.34537,1.33721,1.32432,1.31712,1.30687,1.29657,1.29285,1.28732,1.28142,1.27042,1.26335,1.25817,1.25283,1.24492,1.24006,1.23586,1.22976,1.21965,1.21302,1.20807,1.20007,1.19311,1.18657,1.18372,1.17765,1.1689,1.16243,1.15858,1.15031,1.14554,1.14142,1.13634,1.12906,1.12356,1.1171,1.11282,1.1108,1.10663,1.09808,1.08971,1.07938,1.07509,1.07127,1.06814,1.06184,1.053,1.04962,1.04352,1.03874,1.03672,1.03416,1.03115,1.02201,1.01574,1.00829,1.00439,0.999857,0.994778,0.991202,0.989156,0.987037,0.978006,0.974746,0.971395,0.962709,0.961445,0.953984,0.947054,0.939572,0.93622,0.934287,0.9302,0.928448,0.926016,0.919454,0.917292,0.914619,0.910796,0.903671,0.896598,0.889671,0.887527,0.883948,0.880298,0.877813,0.875984,0.873709,0.872142,0.868231,0.866057,0.862663,0.859206,0.853553,0.85089,0.846009,0.845291,0.840762,0.836909,0.835012,0.833862,0.832656,0.82652,0.820458,0.816002,0.814967,0.811374,0.81042,0.806913,0.80134,0.799546,0.798485,0.796314,0.795548,0.793488,0.790375,0.784293,0.782534,0.777398,0.774558,0.771438,0.767506,0.765402,0.760064,0.756784,0.753403,0.748104,0.746524,0.739733,0.731335,0.726668,0.724832,0.721598,0.718098],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'training',\n",
       "},\n",
       "{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253],\n",
       "y: [10.0561,9.22557,8.49777,7.86424,7.28845,6.81282,6.37837,6.00189,5.67882,5.38262,5.13387,4.91264,4.69061,4.50235,4.36535,4.23529,4.14681,4.05023,3.96072,3.89294,3.82952,3.7683,3.73189,3.69655,3.65384,3.62042,3.58733,3.55773,3.52884,3.51206,3.48818,3.48366,3.46382,3.45184,3.43305,3.41131,3.4006,3.38973,3.39104,3.38794,3.38795,3.37318,3.37054,3.36355,3.35803,3.35325,3.35468,3.35564,3.34989,3.33724,3.32507,3.32301,3.324,3.32181,3.32299,3.31613,3.31087,3.3026,3.29749,3.30193,3.29847,3.29313,3.29238,3.28878,3.28255,3.27481,3.28043,3.27416,3.27452,3.27038,3.26544,3.26066,3.25159,3.24865,3.24293,3.24436,3.24406,3.24996,3.24692,3.24069,3.24195,3.24096,3.23563,3.22932,3.22624,3.2196,3.21436,3.21051,3.20747,3.20171,3.20228,3.2019,3.2046,3.20266,3.2011,3.19869,3.18963,3.18942,3.18972,3.1879,3.18479,3.18363,3.18279,3.18191,3.17779,3.17437,3.17654,3.17907,3.18235,3.17919,3.18044,3.17766,3.178,3.17349,3.16936,3.16752,3.16922,3.16851,3.16509,3.16597,3.15708,3.15983,3.16377,3.16448,3.1654,3.16495,3.16379,3.16375,3.16375,3.16184,3.15606,3.15646,3.15339,3.1498,3.14532,3.14547,3.1439,3.1445,3.14245,3.14062,3.1408,3.14321,3.14248,3.14276,3.13932,3.13995,3.13995,3.14061,3.13654,3.13678,3.13617,3.13171,3.13191,3.13045,3.13151,3.13073,3.13084,3.12941,3.12938,3.12683,3.12606,3.12725,3.12928,3.12693,3.12513,3.12398,3.12505,3.12487,3.12163,3.1205,3.11907,3.1196,3.11856,3.11602,3.11612,3.11416,3.11222,3.11615,3.11399,3.11368,3.11329,3.10979,3.11048,3.10932,3.10436,3.10405,3.10207,3.10424,3.10231,3.10197,3.10211,3.10109,3.10173,3.10062,3.0972,3.09627,3.09523,3.09635,3.09698,3.09921,3.09492,3.09651,3.09601,3.09672,3.09648,3.09764,3.09684,3.09741,3.09617,3.0968,3.09877,3.09826,3.09692,3.09679,3.09768,3.09764,3.09674,3.09653,3.09556,3.09545,3.09575,3.09436,3.09373,3.09479,3.09398,3.09447,3.09732,3.0982,3.09722,3.09656,3.09766,3.09915,3.09893,3.09859,3.09929,3.09968,3.10011,3.09946,3.10197,3.10287,3.10139,3.10042,3.10015,3.10031,3.09903,3.09986,3.09952,3.1006,3.10013,3.10236,3.1033,3.10286,3.10244],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'validation',\n",
       "},\n",
       "],\n",
       "    {\n",
       "      width: 600,\n",
       "      height: 400,\n",
       "      title: '',\n",
       "      showlegend: true,\n",
       "      xaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'iteration',\n",
       "        },\n",
       "      font: {\n",
       "        size: 10,\n",
       "        },\n",
       "      yaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'loss',\n",
       "        },\n",
       "      margin: {\n",
       "        l: 50,\n",
       "        r: 50,\n",
       "        b: 50,\n",
       "        t: 50,\n",
       "      },\n",
       "    },\n",
       "    {\n",
       "      modeBarButtonsToRemove: ['sendDataToCloud'],\n",
       "      displaylogo: false,displayModeBar: false,\n",
       "    }\n",
       "  );\n",
       "</script>\n",
       "</div><div style='grid-row:2 / span 1; grid-column:1 / span 1;'>\n",
       "<div id=\"chart_1bed_4c80_d5c9_1626self_eval_item1\" style=\"display: inline-block;\" ></div>\n",
       "<script>\n",
       "  Plotly.newPlot(\n",
       "    'chart_1bed_4c80_d5c9_1626self_eval_item1',\n",
       "    [{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253],\n",
       "y: [9.54496,8.75996,8.05847,7.43731,6.88201,6.39548,5.95477,5.5684,5.22204,4.90593,4.62768,4.37758,4.14785,3.94355,3.76465,3.60456,3.46105,3.33642,3.22633,3.12203,3.03126,2.9442,2.86585,2.79718,2.73046,2.66972,2.62021,2.5734,2.52058,2.4709,2.43823,2.40179,2.35831,2.32557,2.28771,2.25648,2.233,2.20624,2.1924,2.17029,2.14648,2.11693,2.09394,2.06671,2.05293,2.04022,2.02814,2.01794,2.00412,1.99402,1.9868,1.97048,1.95653,1.95163,1.94604,1.92896,1.91577,1.91191,1.90273,1.88713,1.86877,1.85749,1.84807,1.84366,1.82866,1.82035,1.81516,1.80138,1.7843,1.77773,1.7709,1.76434,1.74896,1.73351,1.72607,1.71951,1.7098,1.70057,1.69336,1.68082,1.66609,1.66115,1.64984,1.64347,1.63475,1.6251,1.6064,1.59207,1.58828,1.57633,1.56624,1.56034,1.55187,1.53818,1.5258,1.52151,1.51607,1.51318,1.50352,1.49576,1.48304,1.47578,1.46798,1.46378,1.45782,1.44703,1.44316,1.43704,1.42924,1.42703,1.42025,1.40825,1.40095,1.39546,1.39027,1.38558,1.38241,1.37494,1.36785,1.35627,1.34537,1.33721,1.32432,1.31712,1.30687,1.29657,1.29285,1.28732,1.28142,1.27042,1.26335,1.25817,1.25283,1.24492,1.24006,1.23586,1.22976,1.21965,1.21302,1.20807,1.20007,1.19311,1.18657,1.18372,1.17765,1.1689,1.16243,1.15858,1.15031,1.14554,1.14142,1.13634,1.12906,1.12356,1.1171,1.11282,1.1108,1.10663,1.09808,1.08971,1.07938,1.07509,1.07127,1.06814,1.06184,1.053,1.04962,1.04352,1.03874,1.03672,1.03416,1.03115,1.02201,1.01574,1.00829,1.00439,0.999857,0.994778,0.991202,0.989156,0.987037,0.978006,0.974746,0.971395,0.962709,0.961445,0.953984,0.947054,0.939572,0.93622,0.934287,0.9302,0.928448,0.926016,0.919454,0.917292,0.914619,0.910796,0.903671,0.896598,0.889671,0.887527,0.883948,0.880298,0.877813,0.875984,0.873709,0.872142,0.868231,0.866057,0.862663,0.859206,0.853553,0.85089,0.846009,0.845291,0.840762,0.836909,0.835012,0.833862,0.832656,0.82652,0.820458,0.816002,0.814967,0.811374,0.81042,0.806913,0.80134,0.799546,0.798485,0.796314,0.795548,0.793488,0.790375,0.784293,0.782534,0.777398,0.774558,0.771438,0.767506,0.765402,0.760064,0.756784,0.753403,0.748104,0.746524,0.739733,0.731335,0.726668,0.724832,0.721598,0.718098],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'training',\n",
       "},\n",
       "{\n",
       "x: [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253],\n",
       "y: [10.0561,9.22557,8.49777,7.86424,7.28845,6.81282,6.37837,6.00189,5.67882,5.38262,5.13387,4.91264,4.69061,4.50235,4.36535,4.23529,4.14681,4.05023,3.96072,3.89294,3.82952,3.7683,3.73189,3.69655,3.65384,3.62042,3.58733,3.55773,3.52884,3.51206,3.48818,3.48366,3.46382,3.45184,3.43305,3.41131,3.4006,3.38973,3.39104,3.38794,3.38795,3.37318,3.37054,3.36355,3.35803,3.35325,3.35468,3.35564,3.34989,3.33724,3.32507,3.32301,3.324,3.32181,3.32299,3.31613,3.31087,3.3026,3.29749,3.30193,3.29847,3.29313,3.29238,3.28878,3.28255,3.27481,3.28043,3.27416,3.27452,3.27038,3.26544,3.26066,3.25159,3.24865,3.24293,3.24436,3.24406,3.24996,3.24692,3.24069,3.24195,3.24096,3.23563,3.22932,3.22624,3.2196,3.21436,3.21051,3.20747,3.20171,3.20228,3.2019,3.2046,3.20266,3.2011,3.19869,3.18963,3.18942,3.18972,3.1879,3.18479,3.18363,3.18279,3.18191,3.17779,3.17437,3.17654,3.17907,3.18235,3.17919,3.18044,3.17766,3.178,3.17349,3.16936,3.16752,3.16922,3.16851,3.16509,3.16597,3.15708,3.15983,3.16377,3.16448,3.1654,3.16495,3.16379,3.16375,3.16375,3.16184,3.15606,3.15646,3.15339,3.1498,3.14532,3.14547,3.1439,3.1445,3.14245,3.14062,3.1408,3.14321,3.14248,3.14276,3.13932,3.13995,3.13995,3.14061,3.13654,3.13678,3.13617,3.13171,3.13191,3.13045,3.13151,3.13073,3.13084,3.12941,3.12938,3.12683,3.12606,3.12725,3.12928,3.12693,3.12513,3.12398,3.12505,3.12487,3.12163,3.1205,3.11907,3.1196,3.11856,3.11602,3.11612,3.11416,3.11222,3.11615,3.11399,3.11368,3.11329,3.10979,3.11048,3.10932,3.10436,3.10405,3.10207,3.10424,3.10231,3.10197,3.10211,3.10109,3.10173,3.10062,3.0972,3.09627,3.09523,3.09635,3.09698,3.09921,3.09492,3.09651,3.09601,3.09672,3.09648,3.09764,3.09684,3.09741,3.09617,3.0968,3.09877,3.09826,3.09692,3.09679,3.09768,3.09764,3.09674,3.09653,3.09556,3.09545,3.09575,3.09436,3.09373,3.09479,3.09398,3.09447,3.09732,3.0982,3.09722,3.09656,3.09766,3.09915,3.09893,3.09859,3.09929,3.09968,3.10011,3.09946,3.10197,3.10287,3.10139,3.10042,3.10015,3.10031,3.09903,3.09986,3.09952,3.1006,3.10013,3.10236,3.1033,3.10286,3.10244],\n",
       "type: 'scatter',\n",
       "mode: 'lines',\n",
       "line: {\n",
       "  dash: 'solid',\n",
       "  width: 1\n",
       "},\n",
       "name: 'validation',\n",
       "},\n",
       "],\n",
       "    {\n",
       "      width: 600,\n",
       "      height: 400,\n",
       "      title: '',\n",
       "      showlegend: true,\n",
       "      xaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'iteration',\n",
       "        },\n",
       "      font: {\n",
       "        size: 10,\n",
       "        },\n",
       "      yaxis: {\n",
       "        ticks: 'outside',\n",
       "        showgrid: true,\n",
       "        zeroline: false,\n",
       "        showline: true,\n",
       "        title: 'rmse',\n",
       "        },\n",
       "      margin: {\n",
       "        l: 50,\n",
       "        r: 50,\n",
       "        b: 50,\n",
       "        t: 50,\n",
       "      },\n",
       "    },\n",
       "    {\n",
       "      modeBarButtonsToRemove: ['sendDataToCloud'],\n",
       "      displaylogo: false,displayModeBar: false,\n",
       "    }\n",
       "  );\n",
       "</script>\n",
       "</div></div></div><div id=\"1bed-4c80-d5c9-1626_body_variable_importance\" class=\"tab_content\"><p><a target=\"_blank\" href=\"https://ydf.readthedocs.io/en/latest/cli_user_manual#variable-importances\">Variable importances</a> measure the importance of an input feature for a model.</p><div id=\"1bed-4c80-d5c9-1626_vi\" class=\"variable_importance\"><select onchange=\"ydfShowVariableImportance('1bed-4c80-d5c9-1626_vi')\"><option value=\"INV_MEAN_MIN_DEPTH\">INV_MEAN_MIN_DEPTH</option><option value=\"NUM_AS_ROOT\">NUM_AS_ROOT</option><option value=\"NUM_NODES\">NUM_NODES</option><option value=\"SUM_SCORE\">SUM_SCORE</option></select><div id=\"1bed-4c80-d5c9-1626_vi_body_INV_MEAN_MIN_DEPTH\" class=\"content selected\"><pre class=\"ydf_pre\">    1.               &quot;phi&quot;  0.195385 ################\n",
       "    2.            &quot;psa_00&quot;  0.195189 ###############\n",
       "    3.                 &quot;x&quot;  0.194150 ##############\n",
       "    4.            &quot;lan_03&quot;  0.192327 ############\n",
       "    5.            &quot;car_00&quot;  0.192101 ############\n",
       "    6.             &quot;pw_00&quot;  0.190861 ###########\n",
       "    7.            &quot;psa_04&quot;  0.190556 ###########\n",
       "    8.            &quot;car_01&quot;  0.190037 ##########\n",
       "    9.             &quot;dw_07&quot;  0.187981 ########\n",
       "   10.               &quot;lat&quot;  0.187912 ########\n",
       "   11.                 &quot;y&quot;  0.187099 #######\n",
       "   12.             &quot;dw_11&quot;  0.187074 #######\n",
       "   13.            &quot;lan_02&quot;  0.186615 #######\n",
       "   14.             &quot;pg_02&quot;  0.186613 #######\n",
       "   15.                 &quot;z&quot;  0.186371 ######\n",
       "   16.                &quot;NL&quot;  0.185836 ######\n",
       "   17.            &quot;stv_00&quot;  0.185621 ######\n",
       "   18.            &quot;psa_01&quot;  0.185598 ######\n",
       "   19.           &quot;hs_area&quot;  0.185353 #####\n",
       "   20.             &quot;pg_01&quot;  0.185192 #####\n",
       "   21.         &quot;AREA_SQKM&quot;  0.185186 #####\n",
       "   22.            &quot;lan_06&quot;  0.185148 #####\n",
       "   23.            &quot;lan_14&quot;  0.184989 #####\n",
       "   24.  &quot;total_households&quot;  0.184891 #####\n",
       "   25.             &quot;dw_04&quot;  0.184841 #####\n",
       "   26.             &quot;dw_08&quot;  0.184838 #####\n",
       "   27. &quot;total_individuals&quot;  0.184778 #####\n",
       "   28.             &quot;dw_02&quot;  0.184445 ####\n",
       "   29.            &quot;psa_03&quot;  0.184327 ####\n",
       "   30.             &quot;pw_04&quot;  0.183893 ####\n",
       "   31.             &quot;dw_06&quot;  0.183879 ####\n",
       "   32.            &quot;lgt_00&quot;  0.183848 ####\n",
       "   33.             &quot;pw_02&quot;  0.183825 ####\n",
       "   34.            &quot;lan_11&quot;  0.183784 ####\n",
       "   35.            &quot;lan_04&quot;  0.183577 ###\n",
       "   36.            &quot;stv_01&quot;  0.183547 ###\n",
       "   37.             &quot;pw_05&quot;  0.183386 ###\n",
       "   38.            &quot;lan_08&quot;  0.183284 ###\n",
       "   39.             &quot;pg_00&quot;  0.183140 ###\n",
       "   40.            &quot;lan_09&quot;  0.183098 ###\n",
       "   41.             &quot;pw_01&quot;  0.182884 ###\n",
       "   42.            &quot;lan_10&quot;  0.182841 ###\n",
       "   43.             &quot;pw_06&quot;  0.182764 ###\n",
       "   44.             &quot;dw_05&quot;  0.182264 ##\n",
       "   45.            &quot;lln_01&quot;  0.182256 ##\n",
       "   46.             &quot;dw_01&quot;  0.182161 ##\n",
       "   47.             &quot;dw_03&quot;  0.182095 ##\n",
       "   48.             &quot;dw_10&quot;  0.181996 ##\n",
       "   49.             &quot;dw_09&quot;  0.181933 ##\n",
       "   50.             &quot;pg_03&quot;  0.181681 ##\n",
       "   51.             &quot;pw_03&quot;  0.181477 #\n",
       "   52.            &quot;lan_05&quot;  0.181416 #\n",
       "   53.            &quot;lln_00&quot;  0.181379 #\n",
       "   54.             &quot;dw_00&quot;  0.181265 #\n",
       "   55.            &quot;lan_07&quot;  0.181262 #\n",
       "   56.            &quot;lan_01&quot;  0.180975 #\n",
       "   57.             &quot;pg_04&quot;  0.180892 #\n",
       "   58.               &quot;lon&quot;  0.180704 #\n",
       "   59.            &quot;lan_00&quot;  0.180475 \n",
       "   60.           &quot;id_area&quot;  0.180364 \n",
       "   61.            &quot;psa_02&quot;  0.180324 \n",
       "   62.            &quot;lan_12&quot;  0.179719 \n",
       "</pre></div><div id=\"1bed-4c80-d5c9-1626_vi_body_NUM_AS_ROOT\" class=\"content\"><pre class=\"ydf_pre\">    1.            &quot;psa_00&quot; 15.000000 ################\n",
       "    2.               &quot;phi&quot; 12.000000 ############\n",
       "    3.            &quot;psa_04&quot; 11.000000 ###########\n",
       "    4.             &quot;pw_00&quot; 11.000000 ###########\n",
       "    5.             &quot;dw_07&quot;  8.000000 ########\n",
       "    6.               &quot;lat&quot;  8.000000 ########\n",
       "    7.            &quot;stv_00&quot;  7.000000 ######\n",
       "    8.            &quot;car_00&quot;  7.000000 ######\n",
       "    9.            &quot;car_01&quot;  7.000000 ######\n",
       "   10.            &quot;lan_03&quot;  7.000000 ######\n",
       "   11.            &quot;lan_14&quot;  7.000000 ######\n",
       "   12.                 &quot;x&quot;  7.000000 ######\n",
       "   13.                 &quot;z&quot;  7.000000 ######\n",
       "   14.             &quot;dw_11&quot;  6.000000 #####\n",
       "   15.                 &quot;y&quot;  6.000000 #####\n",
       "   16.             &quot;dw_04&quot;  5.000000 ####\n",
       "   17.            &quot;lan_02&quot;  5.000000 ####\n",
       "   18.             &quot;pg_01&quot;  5.000000 ####\n",
       "   19.             &quot;pg_02&quot;  5.000000 ####\n",
       "   20.             &quot;pw_04&quot;  5.000000 ####\n",
       "   21.             &quot;dw_06&quot;  4.000000 ###\n",
       "   22.            &quot;psa_01&quot;  4.000000 ###\n",
       "   23.            &quot;lan_04&quot;  4.000000 ###\n",
       "   24.            &quot;lgt_00&quot;  4.000000 ###\n",
       "   25.             &quot;pw_06&quot;  4.000000 ###\n",
       "   26.           &quot;hs_area&quot;  4.000000 ###\n",
       "   27. &quot;total_individuals&quot;  3.000000 ##\n",
       "   28.             &quot;dw_02&quot;  3.000000 ##\n",
       "   29.             &quot;dw_05&quot;  3.000000 ##\n",
       "   30.            &quot;lan_08&quot;  3.000000 ##\n",
       "   31.             &quot;pg_00&quot;  3.000000 ##\n",
       "   32.             &quot;pw_01&quot;  3.000000 ##\n",
       "   33.             &quot;pw_02&quot;  3.000000 ##\n",
       "   34.             &quot;pw_05&quot;  3.000000 ##\n",
       "   35.         &quot;AREA_SQKM&quot;  3.000000 ##\n",
       "   36.  &quot;total_households&quot;  2.000000 #\n",
       "   37.             &quot;dw_03&quot;  2.000000 #\n",
       "   38.             &quot;dw_08&quot;  2.000000 #\n",
       "   39.             &quot;dw_09&quot;  2.000000 #\n",
       "   40.            &quot;stv_01&quot;  2.000000 #\n",
       "   41.            &quot;lan_06&quot;  2.000000 #\n",
       "   42.            &quot;lan_11&quot;  2.000000 #\n",
       "   43.                &quot;NL&quot;  2.000000 #\n",
       "   44.           &quot;id_area&quot;  2.000000 #\n",
       "   45.            &quot;psa_03&quot;  1.000000 \n",
       "   46.            &quot;lln_00&quot;  1.000000 \n",
       "   47.               &quot;lon&quot;  1.000000 \n",
       "</pre></div><div id=\"1bed-4c80-d5c9-1626_vi_body_NUM_NODES\" class=\"content\"><pre class=\"ydf_pre\">    1.               &quot;phi&quot; 156.000000 ################\n",
       "    2.                 &quot;x&quot; 137.000000 #############\n",
       "    3.            &quot;psa_00&quot; 130.000000 ############\n",
       "    4.            &quot;lan_03&quot; 105.000000 #########\n",
       "    5.            &quot;psa_04&quot; 102.000000 #########\n",
       "    6.            &quot;lan_09&quot; 93.000000 ########\n",
       "    7.            &quot;car_01&quot; 92.000000 #######\n",
       "    8.            &quot;lan_06&quot; 90.000000 #######\n",
       "    9.            &quot;car_00&quot; 88.000000 #######\n",
       "   10.             &quot;dw_07&quot; 87.000000 #######\n",
       "   11.            &quot;psa_01&quot; 87.000000 #######\n",
       "   12.             &quot;pg_02&quot; 85.000000 ######\n",
       "   13.                 &quot;y&quot; 85.000000 ######\n",
       "   14.            &quot;psa_03&quot; 83.000000 ######\n",
       "   15. &quot;total_individuals&quot; 82.000000 ######\n",
       "   16.         &quot;AREA_SQKM&quot; 81.000000 ######\n",
       "   17.             &quot;dw_01&quot; 80.000000 ######\n",
       "   18.            &quot;lan_02&quot; 79.000000 ######\n",
       "   19.             &quot;pw_02&quot; 79.000000 ######\n",
       "   20.             &quot;dw_11&quot; 77.000000 #####\n",
       "   21.             &quot;dw_08&quot; 76.000000 #####\n",
       "   22.                &quot;NL&quot; 76.000000 #####\n",
       "   23.             &quot;dw_06&quot; 75.000000 #####\n",
       "   24.            &quot;lgt_00&quot; 75.000000 #####\n",
       "   25.             &quot;pw_01&quot; 74.000000 #####\n",
       "   26.               &quot;lat&quot; 73.000000 #####\n",
       "   27.            &quot;lan_04&quot; 71.000000 #####\n",
       "   28.             &quot;pg_03&quot; 71.000000 #####\n",
       "   29.            &quot;lan_11&quot; 70.000000 #####\n",
       "   30.  &quot;total_households&quot; 68.000000 ####\n",
       "   31.             &quot;dw_00&quot; 68.000000 ####\n",
       "   32.            &quot;lan_07&quot; 68.000000 ####\n",
       "   33.            &quot;lan_05&quot; 67.000000 ####\n",
       "   34.            &quot;lan_10&quot; 67.000000 ####\n",
       "   35.             &quot;pg_01&quot; 67.000000 ####\n",
       "   36.                 &quot;z&quot; 66.000000 ####\n",
       "   37.            &quot;lan_08&quot; 63.000000 ####\n",
       "   38.            &quot;stv_00&quot; 62.000000 ####\n",
       "   39.             &quot;dw_02&quot; 61.000000 ###\n",
       "   40.             &quot;dw_04&quot; 60.000000 ###\n",
       "   41.             &quot;pw_00&quot; 60.000000 ###\n",
       "   42.             &quot;dw_03&quot; 59.000000 ###\n",
       "   43.             &quot;dw_09&quot; 59.000000 ###\n",
       "   44.             &quot;pw_05&quot; 59.000000 ###\n",
       "   45.             &quot;dw_10&quot; 58.000000 ###\n",
       "   46.             &quot;pg_04&quot; 58.000000 ###\n",
       "   47.               &quot;lon&quot; 58.000000 ###\n",
       "   48.            &quot;stv_01&quot; 56.000000 ###\n",
       "   49.            &quot;lan_00&quot; 55.000000 ###\n",
       "   50.             &quot;pw_06&quot; 54.000000 ###\n",
       "   51.            &quot;lan_14&quot; 53.000000 ##\n",
       "   52.           &quot;hs_area&quot; 53.000000 ##\n",
       "   53.             &quot;dw_05&quot; 52.000000 ##\n",
       "   54.            &quot;lan_01&quot; 52.000000 ##\n",
       "   55.             &quot;pw_03&quot; 50.000000 ##\n",
       "   56.            &quot;psa_02&quot; 49.000000 ##\n",
       "   57.            &quot;lln_01&quot; 49.000000 ##\n",
       "   58.            &quot;lan_12&quot; 49.000000 ##\n",
       "   59.             &quot;pg_00&quot; 47.000000 ##\n",
       "   60.             &quot;pw_04&quot; 44.000000 #\n",
       "   61.            &quot;lln_00&quot; 34.000000 \n",
       "   62.           &quot;id_area&quot; 30.000000 \n",
       "</pre></div><div id=\"1bed-4c80-d5c9-1626_vi_body_SUM_SCORE\" class=\"content\"><pre class=\"ydf_pre\">    1.            &quot;psa_00&quot; 684071.710775 ################\n",
       "    2.            &quot;car_00&quot; 164343.258912 ###\n",
       "    3.            &quot;car_01&quot; 108396.973191 ##\n",
       "    4.             &quot;pw_00&quot; 98176.426756 ##\n",
       "    5.             &quot;pg_00&quot; 21287.915592 \n",
       "    6.               &quot;phi&quot; 16547.851844 \n",
       "    7.                &quot;NL&quot; 12628.184119 \n",
       "    8.             &quot;pg_01&quot; 11428.908723 \n",
       "    9.                 &quot;x&quot; 11015.923928 \n",
       "   10.            &quot;lan_03&quot; 9468.093177 \n",
       "   11.            &quot;lln_01&quot; 9423.243907 \n",
       "   12.            &quot;psa_01&quot; 8876.341105 \n",
       "   13.               &quot;lat&quot; 7387.266547 \n",
       "   14.            &quot;psa_04&quot; 7051.172260 \n",
       "   15.               &quot;lon&quot; 6898.491520 \n",
       "   16.             &quot;dw_01&quot; 6604.909577 \n",
       "   17.            &quot;lan_06&quot; 6152.510726 \n",
       "   18.            &quot;lan_09&quot; 6048.598911 \n",
       "   19.            &quot;lan_00&quot; 5877.747042 \n",
       "   20.                 &quot;z&quot; 5716.555346 \n",
       "   21.            &quot;stv_00&quot; 4000.523010 \n",
       "   22.         &quot;AREA_SQKM&quot; 3883.563868 \n",
       "   23.             &quot;pg_03&quot; 3742.423118 \n",
       "   24.            &quot;lgt_00&quot; 3602.128089 \n",
       "   25.            &quot;lan_05&quot; 3581.994964 \n",
       "   26.             &quot;pw_02&quot; 3509.080112 \n",
       "   27.            &quot;stv_01&quot; 3486.128373 \n",
       "   28.            &quot;lan_10&quot; 3465.334841 \n",
       "   29.             &quot;dw_08&quot; 3380.925950 \n",
       "   30.             &quot;pw_01&quot; 3251.076833 \n",
       "   31. &quot;total_individuals&quot; 3036.503215 \n",
       "   32.            &quot;lan_07&quot; 2998.345292 \n",
       "   33.             &quot;dw_00&quot; 2962.750568 \n",
       "   34.            &quot;lan_11&quot; 2959.341993 \n",
       "   35.                 &quot;y&quot; 2650.075923 \n",
       "   36.            &quot;lan_01&quot; 2491.464747 \n",
       "   37.             &quot;pg_04&quot; 2377.260744 \n",
       "   38.             &quot;dw_07&quot; 2369.723619 \n",
       "   39.             &quot;dw_02&quot; 2218.396052 \n",
       "   40.             &quot;dw_11&quot; 2192.155177 \n",
       "   41.            &quot;psa_03&quot; 2130.367256 \n",
       "   42.             &quot;pw_06&quot; 2110.020859 \n",
       "   43.             &quot;pg_02&quot; 1922.290616 \n",
       "   44.             &quot;pw_04&quot; 1844.043854 \n",
       "   45.            &quot;lan_04&quot; 1835.289052 \n",
       "   46.            &quot;lan_02&quot; 1824.216238 \n",
       "   47.             &quot;dw_05&quot; 1748.012328 \n",
       "   48.             &quot;dw_06&quot; 1655.205245 \n",
       "   49.            &quot;lan_12&quot; 1634.897885 \n",
       "   50.           &quot;hs_area&quot; 1589.357554 \n",
       "   51.            &quot;lan_08&quot; 1409.470195 \n",
       "   52.             &quot;dw_10&quot; 1301.647140 \n",
       "   53.           &quot;id_area&quot; 1300.706928 \n",
       "   54.  &quot;total_households&quot; 1265.186294 \n",
       "   55.             &quot;dw_09&quot; 1199.108052 \n",
       "   56.             &quot;pw_03&quot; 1189.174492 \n",
       "   57.            &quot;lan_14&quot; 1138.566721 \n",
       "   58.             &quot;pw_05&quot; 1112.977012 \n",
       "   59.             &quot;dw_04&quot; 1061.754152 \n",
       "   60.            &quot;lln_00&quot; 1044.853583 \n",
       "   61.             &quot;dw_03&quot; 902.296045 \n",
       "   62.            &quot;psa_02&quot; 858.213645 \n",
       "</pre></div></div><p>Those variable importances are computed during training. More, and possibly more informative, variable importances are available when analyzing a model on a test dataset.</p></div><div id=\"1bed-4c80-d5c9-1626_body_structure\" class=\"tab_content\"><b>Num trees</b> : 223<br><p>Only printing the first tree.</p><pre class=\"ydf_pre\">Tree #0:\n",
       "    &quot;psa_00&quot;&gt;=0.328968 [s:55.9435 n:2288 np:931 miss:0] ; pred:4.35156e-08\n",
       "        (pos) &quot;car_00&quot;&gt;=0.22036 [s:15.1685 n:931 np:129 miss:1] ; pred:0.903004\n",
       "        |        (pos) &quot;car_01&quot;&gt;=0.616083 [s:18.3661 n:129 np:105 miss:1] ; pred:-0.0680937\n",
       "        |        |        (pos) &quot;lln_01&quot;&gt;=0.964208 [s:6.2625 n:105 np:35 miss:0] ; pred:0.136796\n",
       "        |        |        |        (pos) &quot;psa_01&quot;&gt;=0.460468 [s:7.63644 n:35 np:24 miss:1] ; pred:0.490702\n",
       "        |        |        |        |        (pos) pred:0.303619\n",
       "        |        |        |        |        (neg) pred:0.898885\n",
       "        |        |        |        (neg) &quot;dw_00&quot;&gt;=0.933523 [s:3.90528 n:70 np:17 miss:0] ; pred:-0.0401576\n",
       "        |        |        |                 (pos) pred:0.308773\n",
       "        |        |        |                 (neg) pred:-0.152079\n",
       "        |        |        (neg) &quot;lan_07&quot;&gt;=0.0425299 [s:6.90304 n:24 np:8 miss:1] ; pred:-0.964485\n",
       "        |        |                 (pos) pred:-1.33605\n",
       "        |        |                 (neg) &quot;dw_04&quot;&gt;=0.000518848 [s:5.51162 n:16 np:11 miss:1] ; pred:-0.778702\n",
       "        |        |                          (pos) pred:-0.620421\n",
       "        |        |                          (neg) pred:-1.12692\n",
       "        |        (neg) &quot;psa_00&quot;&gt;=0.376001 [s:7.34655 n:802 np:515 miss:0] ; pred:1.0592\n",
       "        |                 (pos) &quot;lat&quot;&gt;=-25.008 [s:4.54436 n:515 np:208 miss:0] ; pred:1.26154\n",
       "        |                 |        (pos) &quot;stv_00&quot;&gt;=0.0961884 [s:5.35692 n:208 np:128 miss:1] ; pred:1.52053\n",
       "        |                 |        |        (pos) pred:1.33755\n",
       "        |                 |        |        (neg) pred:1.81329\n",
       "        |                 |        (neg) &quot;car_00&quot;&gt;=0.0973911 [s:6.52777 n:307 np:227 miss:1] ; pred:1.08607\n",
       "        |                 |                 (pos) pred:0.934399\n",
       "        |                 |                 (neg) pred:1.51645\n",
       "        |                 (neg) &quot;pg_00&quot;&gt;=0.996369 [s:3.33487 n:287 np:101 miss:0] ; pred:0.696122\n",
       "        |                          (pos) &quot;pw_01&quot;&gt;=0.0784044 [s:2.76678 n:101 np:89 miss:1] ; pred:0.943941\n",
       "        |                          |        (pos) pred:0.882863\n",
       "        |                          |        (neg) pred:1.39693\n",
       "        |                          (neg) &quot;pw_04&quot;&gt;=0.00971671 [s:4.06134 n:186 np:101 miss:1] ; pred:0.561553\n",
       "        |                                   (pos) pred:0.74643\n",
       "        |                                   (neg) pred:0.341875\n",
       "        (neg) &quot;car_01&quot;&gt;=0.685956 [s:22.9272 n:1357 np:929 miss:1] ; pred:-0.619526\n",
       "                 (pos) &quot;psa_00&quot;&gt;=0.257125 [s:8.43227 n:929 np:603 miss:1] ; pred:-0.294521\n",
       "                 |        (pos) &quot;car_01&quot;&gt;=0.83226 [s:5.77866 n:603 np:259 miss:0] ; pred:-0.0810094\n",
       "                 |        |        (pos) &quot;psa_00&quot;&gt;=0.291445 [s:3.72804 n:259 np:128 miss:1] ; pred:0.196031\n",
       "                 |        |        |        (pos) pred:0.391362\n",
       "                 |        |        |        (neg) pred:0.00517327\n",
       "                 |        |        (neg) &quot;psa_00&quot;&gt;=0.287632 [s:2.34409 n:344 np:173 miss:1] ; pred:-0.289595\n",
       "                 |        |                 (pos) pred:-0.137378\n",
       "                 |        |                 (neg) pred:-0.443592\n",
       "                 |        (neg) &quot;psa_00&quot;&gt;=0.222471 [s:4.49816 n:326 np:191 miss:1] ; pred:-0.689453\n",
       "                 |                 (pos) &quot;car_01&quot;&gt;=0.902798 [s:4.69867 n:191 np:10 miss:0] ; pred:-0.511147\n",
       "                 |                 |        (pos) pred:0.411057\n",
       "                 |                 |        (neg) pred:-0.562097\n",
       "                 |                 (neg) &quot;lon&quot;&gt;=29.2172 [s:6.59755 n:135 np:23 miss:0] ; pred:-0.941724\n",
       "                 |                          (pos) pred:-0.374915\n",
       "                 |                          (neg) pred:-1.05812\n",
       "                 (neg) &quot;car_01&quot;&gt;=0.457494 [s:9.13754 n:428 np:198 miss:1] ; pred:-1.32497\n",
       "                          (pos) &quot;x&quot;&gt;=0.888227 [s:3.003 n:198 np:162 miss:1] ; pred:-0.999172\n",
       "                          |        (pos) &quot;phi&quot;&gt;=0.000486606 [s:2.46156 n:162 np:116 miss:1] ; pred:-1.08086\n",
       "                          |        |        (pos) pred:-0.982063\n",
       "                          |        |        (neg) pred:-1.33001\n",
       "                          |        (neg) &quot;total_individuals&quot;&gt;=5645.66 [s:4.70768 n:36 np:29 miss:1] ; pred:-0.631565\n",
       "                          |                 (pos) pred:-0.738164\n",
       "                          |                 (neg) pred:-0.18994\n",
       "                          (neg) &quot;car_01&quot;&gt;=0.255358 [s:2.80662 n:230 np:122 miss:1] ; pred:-1.60544\n",
       "                                   (pos) &quot;x&quot;&gt;=0.876005 [s:0.894219 n:122 np:105 miss:1] ; pred:-1.44781\n",
       "                                   |        (pos) pred:-1.48586\n",
       "                                   |        (neg) pred:-1.2128\n",
       "                                   (neg) &quot;x&quot;&gt;=0.885648 [s:0.608562 n:108 np:95 miss:1] ; pred:-1.78349\n",
       "                                            (pos) pred:-1.81235\n",
       "                                            (neg) pred:-1.57261\n",
       "</pre></div></div></div>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T15:47:20.476671Z",
     "start_time": "2025-03-29T15:47:20.469945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# List the available variable importances.\n",
    "print(trainer.variable_importances().keys())"
   ],
   "id": "2daabc4a80be7691",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NUM_NODES', 'SUM_SCORE', 'INV_MEAN_MIN_DEPTH', 'NUM_AS_ROOT'])\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The best variable importance (VI) metric to use depends on your goal and the specific properties of your dataset and model. Here's how you can decide:\n",
    "\n",
    "### **1. If you want a model-agnostic approach (more generalizable)**\n",
    "   - **MEAN_{INCREASE, DECREASE}_IN_{metric}**\n",
    "     - **Pros:** Measures the direct impact of a feature on performance (e.g., accuracy, AUC).\n",
    "     - **Cons:** Can be computationally expensive, especially with large datasets.\n",
    "     - **Best for:** Understanding the real-world impact of a feature on model performance.\n",
    "\n",
    "### **2. If you're using Decision Forests (more interpretable)**\n",
    "   - **SUM_SCORE**\n",
    "     - **Pros:** Reflects how often a feature contributes to splits across trees.\n",
    "     - **Cons:** Doesn't measure the direct impact on performance.\n",
    "     - **Best for:** Identifying frequently used features in splits.\n",
    "\n",
    "   - **NUM_AS_ROOT**\n",
    "     - **Pros:** Highlights features that are often chosen for root splits (high impact early on).\n",
    "     - **Cons:** May favor categorical features with high cardinality.\n",
    "     - **Best for:** Finding highly influential features at the start of decision trees.\n",
    "\n",
    "   - **NUM_NODES**\n",
    "     - **Pros:** Measures overall usage of a feature in decision paths.\n",
    "     - **Cons:** Doesn't necessarily correlate with importance for prediction accuracy.\n",
    "     - **Best for:** Identifying frequently used features.\n",
    "\n",
    "   - **INV_MEAN_MIN_DEPTH**\n",
    "     - **Pros:** Prioritizes features that appear early in tree paths.\n",
    "     - **Cons:** Might be biased toward features that correlate with others.\n",
    "     - **Best for:** Understanding hierarchical importance in tree-based models.\n",
    "\n",
    "### **Which one to use?**\n",
    "- **For feature selection:** Start with **MEAN_DECREASE_IN_ACCURACY** or **MEAN_DECREASE_IN_AUC** (if AUC matters).\n",
    "- **For Decision Forests:** Use **INV_MEAN_MIN_DEPTH** and **NUM_AS_ROOT** to identify the most crucial features.\n",
    "- **For interpretability:** Combine multiple metrics, prioritizing **SUM_SCORE** and **NUM_AS_ROOT**."
   ],
   "id": "b1c463b882e0cf66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that the trainer doesn't compute the most important feature key by default. We skip this part.",
   "id": "871a091196582592"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tag_id)",
   "language": "python",
   "name": "tag_id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
