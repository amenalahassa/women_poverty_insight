{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-30T13:12:34.189664Z",
     "start_time": "2025-03-30T13:12:32.733179Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow.keras.layers\n",
    "from keras.src.layers import Lambda\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import ydf  # Yggdrasil Decision Forests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from wurlitzer import sys_pipes\n",
    "import keras.layers as preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "import tqdm as tqdm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 10]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-30 09:12:32.901386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743340352.912744 1567528 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743340352.916277 1567528 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1743340352.925991 1567528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743340352.926000 1567528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743340352.926001 1567528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1743340352.926002 1567528 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-03-30 09:12:32.929502: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:12:34.300383Z",
     "start_time": "2025-03-30T13:12:34.253999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Set memory growth to avoid TensorFlow using all GPU memory\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "        # Set TensorFlow to use only the first GPU (if multiple GPUs available)\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "\n",
    "        print(\"Using GPU:\", gpus[0])\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "1cbeeb19f955c7f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:12:34.416939Z",
     "start_time": "2025-03-30T13:12:34.413870Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_eval(model, train_ds, test_ds = None):\n",
    "    # Optionally, add evaluation metrics.\n",
    "    model.compile(metrics=[\"mse\"])\n",
    "    rmse = 0\n",
    "\n",
    "    with sys_pipes():\n",
    "        model.fit(x=train_ds)\n",
    "\n",
    "    if test_ds is not None:\n",
    "        evaluation = model.evaluate(x=test_ds, return_dict=True)\n",
    "        rmse = math.sqrt(evaluation[\"mse\"])\n",
    "\n",
    "    return rmse\n",
    "\n",
    "def latlon_to_xyz(lat, lon):\n",
    "    lat, lon = np.radians(lat), np.radians(lon)\n",
    "    x = np.cos(lat) * np.cos(lon)\n",
    "    y = np.cos(lat) * np.sin(lon)\n",
    "    z = np.sin(lat)\n",
    "    return x, y, z\n",
    "\n",
    "# Example: Normalize Cartesian coordinates between 0 and 1\n",
    "def normalize_xyz(x, y, z):\n",
    "    # Normalizing each coordinate to the [0, 1] range\n",
    "    return (x + 1) / 2, (y + 1) / 2, (z + 1) / 2"
   ],
   "id": "6c9c236a46c60459",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:12:34.519812Z",
     "start_time": "2025-03-30T13:12:34.475749Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ROOT_DIR = \"temporary\"\n",
    "train_df = pd.read_csv(f'{ROOT_DIR}/Train.csv')\n",
    "test_df = pd.read_csv(f'{ROOT_DIR}/Test.csv')\n",
    "vocab_df = pd.read_csv(f'{ROOT_DIR}/variable_descriptions.csv')\n",
    "admin_df = pd.read_csv(f'{ROOT_DIR}/zaf_adminboundaries_tabulardata.csv', sep=\";\")\n",
    "\n",
    "admin_df = admin_df[[\"ADM4_PCODE\", \"AREA_SQKM\", \"ADM2_ID\"]] # ADM3_ID\n",
    "admin_df[\"AREA_SQKM\"] = admin_df[\"AREA_SQKM\"].str.replace(\",\", \".\").astype(float)\n",
    "train_df = pd.merge(train_df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "test_df = pd.merge(test_df, admin_df, on=\"ADM4_PCODE\", how=\"left\")\n",
    "label_column = \"target\"\n",
    "\n",
    "default_columns = [\"ward\", \"ADM4_PCODE\"]\n",
    "nul_cols = [\"dw_12\", \"dw_13\", \"lan_13\", \"pw_08\", \"pw_07\"] # Columns with null values\n",
    "cat_columns = [\"ADM2_ID\"] # Categorical columns\n",
    "ft_columns = default_columns + cat_columns"
   ],
   "id": "baaa89ce9b2530a6",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T13:29:45.099318Z",
     "start_time": "2025-03-30T13:29:45.094764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "encoder = OneHotEncoder()\n",
    "def preprocess_df(input_df, is_train=False):\n",
    "    drop_cols = []\n",
    "    df = input_df.copy()\n",
    "    df = df.drop(nul_cols, axis=1)\n",
    "\n",
    "    ## Create a new feature\n",
    "    df[\"phi\"] = df[\"total_individuals\"] / df[\"total_households\"]\n",
    "    df[\"id_area\"] = df[\"total_individuals\"] / df[\"AREA_SQKM\"]\n",
    "    df[\"hs_area\"] = df[\"total_households\"] / df[\"AREA_SQKM\"]\n",
    "    df[\"cluster\"] = kmeans.fit_predict(df[[\"lon\", \"lat\"]]) if is_train else kmeans.predict(df[[\"lon\", \"lat\"]])\n",
    "    encoded_cluster = encoder.fit_transform(df[[\"cluster\"]]) if is_train else encoder.transform(df[[\"cluster\"]])\n",
    "    encoded_cluster_df = pd.DataFrame(encoded_cluster.toarray(), columns=encoder.get_feature_names_out([\"cluster\"]))\n",
    "    for col in encoded_cluster_df.columns:\n",
    "        df[col] = encoded_cluster_df[col]\n",
    "\n",
    "    ## Transform lat and lon to xyz\n",
    "    df[\"x\"], df[\"y\"], df[\"z\"] = zip(*df.apply(lambda x: latlon_to_xyz(x[\"lat\"], x[\"lon\"]), axis=1))\n",
    "    df[\"x\"], df[\"y\"], df[\"z\"] = zip(*df.apply(lambda x: normalize_xyz(x[\"x\"], x[\"y\"], x[\"z\"]), axis=1))\n",
    "\n",
    "    ## Normalize some columns\n",
    "    norm_cols = [\"phi\", \"NL\", \"id_area\", \"hs_area\"]\n",
    "    df[norm_cols] = scaler.fit_transform(df[norm_cols]) if is_train else scaler.transform(df[norm_cols])\n",
    "\n",
    "    drop_cols = drop_cols + default_columns + cat_columns + [\"cluster\", \"cluster_0\"] # Drop one of the encoded columns, to avoid multicollinearity and the cluster column\n",
    "    if len(drop_cols) > 0:\n",
    "        df.drop(drop_cols, axis=1, inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "## Test preprocess_df\n",
    "# preprocess_df(train_ds_pd, is_train=True).head()"
   ],
   "id": "1359c575af7915c5",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:10:12.031204Z",
     "start_time": "2025-03-30T16:24:04.735269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "all_models = {\n",
    "    \"GBT\": ydf.GradientBoostedTreesLearner,\n",
    "    \"RF\": ydf.RandomForestLearner,\n",
    "}\n",
    "\n",
    "## Split data on train and test based on the zone\n",
    "X = train_df.drop(label_column, axis=1)\n",
    "y = train_df[label_column]\n",
    "g = train_df[\"ADM2_ID\"]\n",
    "\n",
    "## Sample a subset of the zone\n",
    "test_g = g.sample(n=6, random_state=42)\n",
    "train_g = g[~g.isin(test_g)]\n",
    "X_train, X_val = X[g.isin(train_g)], X[g.isin(test_g)]\n",
    "y_train, y_val = y[g.isin(train_g)], y[g.isin(test_g)]\n",
    "\n",
    "X_train = preprocess_df(X_train, is_train=True)\n",
    "X_val = preprocess_df(X_val, is_train=False)\n",
    "X_train[\"target\"] = y_train\n",
    "X_val[\"target\"] = y_val\n",
    "outputs = {}\n",
    "\n",
    "for mn, md in all_models.items():\n",
    "    tuner = ydf.RandomSearchTuner(num_trials=20, automatic_search_space=True)\n",
    "    model = md(label=label_column, task=ydf.Task.REGRESSION, num_threads=32, tuner=tuner)\n",
    "    trainer = model.train(ds=X_train, valid=X_val if mn == \"GBT\" else None)\n",
    "    evaluation = trainer.evaluate(X_val)\n",
    "    outputs[mn] = {\n",
    "        \"evaluation\": evaluation,\n",
    "        \"model\": model,\n",
    "        \"tuner\": tuner,\n",
    "        \"trainer\": trainer,\n",
    "    }\n",
    "\n",
    "    print(f\"{mn}: {evaluation.rmse:.2f}\")\n",
    "# tuning_logs"
   ],
   "id": "3c8e25f8498d5755",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train model on 2509 training examples and 313 validation examples\n",
      "Model trained in 0:24:27.538198\n",
      "GBT: 3.01\n",
      "Train model on 2509 examples\n",
      "Model trained in 1:21:39.314272\n",
      "RF: 3.24\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-30T18:21:02.947565Z",
     "start_time": "2025-03-30T18:21:02.941160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "best_model_name = \"GBT\"\n",
    "# best_hp = outputs[best_model_name][\"hp\"].hyperparameters\n",
    "# best_model = all_models[best_model_name](label=label_column, task=ydf.Task.REGRESSION, num_threads=32, **best_hp)\n",
    "# trainer = best_model.train(ds=X_train)\n",
    "evaluation = outputs[best_model_name][\"trainer\"].evaluate(X_val)\n",
    "print(f\"Best model: {evaluation.rmse:.2f}\")"
   ],
   "id": "800386d3d76ead5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model: 3.01\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can have a better model with tuning the hyperparameters.",
   "id": "4cf8eee884444ee9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_feature_df = preprocess_df(test_df, is_train=False)\n",
    "test_df['target'] = outputs[best_model_name][\"trainer\"].predict(test_feature_df)\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "test_df[['ward', 'target']].to_csv(f'{timestamp}_submission.csv', index=False)"
   ],
   "id": "240c331ac6c33be3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tag_id)",
   "language": "python",
   "name": "tag_id"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
